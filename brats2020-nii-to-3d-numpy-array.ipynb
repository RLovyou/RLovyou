{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Brain Tumor Segmentation (BraTS) 2020 - NII to 3D NumPy Array\n","\n","![CT Image](https://storage.googleapis.com/kaggle-datasets-images/674071/1185670/0d449dc88ac1318321ae8f7de974f0fa/dataset-cover.jpg?t=2020-05-25-13-21-33)\n","\n","- **Author:** *Mariusz Wi≈õniewski*\n","- **Date created:** *April 17th, 2023*\n","- **Last modified:** *April 17th, 2023*\n","\n","## Overview\n","\n","In this notebook, we will convert volumes from the *BraTS2020* dataset from *.NII* to 3D NumPy arrays.\n","\n","All BraTS multimodal scans are available as NIfTI files (.nii.gz) and describe:\n","\n","- native (**T1**),\n","- post-contrast T1-weighted (**T1Gd**),\n","- T2-weighted (**T2**),\n","- T2 Fluid Attenuated Inversion Recovery (**T2-FLAIR**)\n","\n","volumes, and were acquired with different clinical protocols and various scanners from multiple (n=19) institutions.\n","\n","All the imaging datasets have been segmented manually, by one to four raters, following the same annotation protocol, and their annotations were approved by experienced neuro-radiologists. Annotations comprise:\n","\n","- the necrotic and non-enhancing tumor core (**NCR/NET ‚Äî label 1**),\n","- the peritumoral edema (**ED ‚Äî label 2**),\n","- the GD-enhancing tumor (**ET ‚Äî label 4**),\n"," \n","as described both in the [BraTS 2012-2013 TMI paper](https://ieeexplore.ieee.org/document/6975210) and in the [latest BraTS summarizing paper](https://arxiv.org/abs/1811.02629). The provided data are distributed after their pre-processing, i.e., co-registered to the same anatomical template, interpolated to the same resolution ($1 {mm}^3$) and skull-stripped.\n","\n","## References\n","\n","- [üìÑ The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)](https://ieeexplore.ieee.org/document/6975210)\n","- [üìÑ Advancing The Cancer Genome Atlas glioma MRI collections with expert segmentation labels and radiomic features](https://www.nature.com/articles/sdata2017117)\n","- [üìÑ Identifying the Best Machine Learning Algorithms for Brain Tumor Segmentation, Progression Assessment, and Overall Survival Prediction in the BRATS Challenge](https://arxiv.org/abs/1811.02629)"]},{"cell_type":"markdown","metadata":{},"source":["## Import Statements"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-05T23:59:57.437872Z","iopub.status.busy":"2023-05-05T23:59:57.437258Z","iopub.status.idle":"2023-05-05T23:59:58.023373Z","shell.execute_reply":"2023-05-05T23:59:58.021825Z","shell.execute_reply.started":"2023-05-05T23:59:57.437807Z"},"trusted":true},"outputs":[],"source":["import os\n","from glob import glob\n","\n","import nibabel as nib\n","import numpy as np\n","import pandas as pd\n","from scipy import ndimage"]},{"cell_type":"markdown","metadata":{},"source":["## Project Configuration"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T23:59:58.026871Z","iopub.status.busy":"2023-05-05T23:59:58.026442Z","iopub.status.idle":"2023-05-05T23:59:58.033349Z","shell.execute_reply":"2023-05-05T23:59:58.031755Z","shell.execute_reply.started":"2023-05-05T23:59:58.026832Z"},"trusted":true},"outputs":[],"source":["DATA_PATH = './archive_BraTS2022'\n","TRAIN_PATH = f'{DATA_PATH}/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n","TEST_PATH = f'{DATA_PATH}/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n","DATA_TYPES = ['flair', 't1', 't1ce', 't2', 'seg']\n","N_FOLDS = 5"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"markdown","metadata":{},"source":["## Data Distribution"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T23:59:58.036033Z","iopub.status.busy":"2023-05-05T23:59:58.03541Z","iopub.status.idle":"2023-05-06T00:00:03.403092Z","shell.execute_reply":"2023-05-06T00:00:03.401399Z","shell.execute_reply.started":"2023-05-05T23:59:58.03598Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[TRAIN] Number of flair images: 369\n","[TRAIN] Number of t1 images: 369\n","[TRAIN] Number of t1ce images: 369\n","[TRAIN] Number of t2 images: 369\n","[TRAIN] Number of seg images: 369\n","\n","[TEST] Number of flair images: 125\n","[TEST] Number of t1 images: 125\n","[TEST] Number of t1ce images: 125\n","[TEST] Number of t2 images: 125\n","[TEST] Number of seg images: 0\n"]}],"source":["train_data_paths = {\n","    data_type: sorted(\n","        glob(f'{TRAIN_PATH}/**/*_{data_type}.nii')\n","    ) for data_type in DATA_TYPES\n","}\n","train_data_paths['seg'].append(f'{TRAIN_PATH}/BraTS20_Training_355/W39_1998.09.19_Seg.nii')\n","train_data_paths['seg'] = sorted(train_data_paths['seg'])\n","\n","for k, v in train_data_paths.items():\n","    print(f'[TRAIN] Number of {k} images: {len(v)}')\n","print()\n","test_data_paths = {\n","    data_type: sorted(\n","        glob(f'{TEST_PATH}/**/*_{data_type}.nii')\n","    ) for data_type in DATA_TYPES\n","}\n","\n","for k, v in test_data_paths.items():\n","    print(f'[TEST] Number of {k} images: {len(v)}')"]},{"cell_type":"markdown","metadata":{},"source":["## Loading Data and Preprocessing"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T00:00:03.405579Z","iopub.status.busy":"2023-05-06T00:00:03.405173Z","iopub.status.idle":"2023-05-06T00:00:03.415364Z","shell.execute_reply":"2023-05-06T00:00:03.413023Z","shell.execute_reply.started":"2023-05-06T00:00:03.40554Z"},"trusted":true},"outputs":[],"source":["def read_nifti_file(filepath):\n","    \"\"\"Read and load volume\"\"\"\n","    # Read file\n","    scan = nib.load(filepath)\n","    # Get raw data\n","    scan = scan.get_fdata()\n","    return scan\n","\n","\n","# def normalize(volume):\n","#     \"\"\"Normalize the volume\"\"\"\n","#     volume = (volume - np.min(volume)) / (np.max(volume) - np.min(volume))\n","#     return (volume * 255).astype(np.uint8)\n","\n","\n","def process_scan(path):\n","    \"\"\"Read and resize volume\"\"\"\n","    # Read scan\n","    volume = read_nifti_file(path)\n","    # Normalize\n","    # volume = normalize(volume)\n","    # Rotate by -90 degrees\n","    # volume = ndimage.rotate(volume, -90, axes=(0,1), reshape=False, order=1)\n","\n","    return volume"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0. 1. 2. 4.]\n"]}],"source":["file_path = '/Users/choihanjun/Library/Mobile Documents/com~apple~CloudDocs/Downloads/2024-1/[Í∞ïÌôîÌïôÏäµ]/Project/archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_seg.nii'\n","\n","processed_volume = process_scan(file_path)\n","unique_values = np.unique(processed_volume)\n","print(unique_values)"]},{"cell_type":"markdown","metadata":{},"source":["# Visualization"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","[-1, -1, -1, 0, 0, 0, 1, 1, 1, -1, -1, -1, 0, 0, 1, 1, 1, -1, -1, -1, 0, 0, 0, 1, 1, 1]\n","[-1, 0, 1, -1, 0, 1, -1, 0, 1, -1, 0, 1, -1, 1, -1, 0, 1, -1, 0, 1, -1, 0, 1, -1, 0, 1]\n"]}],"source":["object_list = []\n","# processed_volume.shape = (240, 240, 155)\n","dx = []\n","dy = []\n","dz = []\n","\n","for x in range(-1, 2):  # -1, 0, 1\n","    for y in range(-1, 2):\n","        for z in range(-1, 2):\n","            if x == 0 and y == 0 and z == 0:\n","                continue  # Ï§ëÏã¨Ï†ê Ï†úÏô∏\n","            dx.append(x)\n","            dy.append(y)\n","            dz.append(z)\n","\n","print(dx)\n","print(dy)\n","print(dz)            \n","    "]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["BBox from (66, 99, 39) to (119, 160, 82)\n","BBox from (75, 115, 53) to (75, 115, 53)\n","BBox from (112, 121, 50) to (112, 121, 50)\n"]}],"source":["from collections import deque\n","\n","\n","\n","def make_bbox(file_path):\n","    file_path = '/Users/choihanjun/Library/Mobile Documents/com~apple~CloudDocs/Downloads/2024-1/[Í∞ïÌôîÌïôÏäµ]/Project/archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_seg.nii'\n","    processed_volume = process_scan(file_path)  \n","    visited = np.zeros(processed_volume.shape)\n","    len_z, len_y, len_x = processed_volume.shape\n","    \n","    def check(visited, nxt_z, nxt_y, nxt_x):\n","        # Î∞ñÏúºÎ°ú ÎÇòÍ∞ÄÏßÄ ÏïäÏïòÍ≥†, Î∞©Î¨∏ÌïòÏßÄ ÏïäÏïòÍ≥†, tumorÏù¥ÎùºÎ©¥ nxt Î∞©Î¨∏ Ï°∞Í±¥Ïù¥ Îê®.\n","        if 0 <= nxt_z < visited.shape[0] and \\\n","            0 <= nxt_y < visited.shape[1] and \\\n","                0 <=  nxt_x < visited.shape[2] and \\\n","                    visited[nxt_z][nxt_y][nxt_x] != 1 and \\\n","                        processed_volume[nxt_z][nxt_y][nxt_x] == 4:\n","            return True\n","        else:\n","            return False\n","        \n","    def BFS(z, y, x):\n","        deq = deque([(z, y, x)])\n","        object_list = [(z, y, x)]\n","        while deq:\n","            now_pos = deq.popleft()\n","            for i in range(len(dx)):\n","                nxt_z, nxt_y, nxt_x = now_pos[0] + dz[i], now_pos[1] + dy[i], now_pos[2] + dx[i]\n","                if check(visited, nxt_z, nxt_y, nxt_x):\n","                    visited[nxt_z][nxt_y][nxt_x] = 1\n","                    deq.appendleft((nxt_z, nxt_y, nxt_x))\n","                    object_list.append((nxt_z, nxt_y, nxt_x))\n","                    \n","        if object_list:\n","            zs, ys, xs = zip(*object_list)\n","            min_z, max_z, min_y, max_y, min_x, max_x = min(zs), max(zs), min(ys), max(ys), min(xs), max(xs)\n","            return min_z, min_y, min_x, max_z, max_y, max_x\n","        else:\n","            return None\n","    \n","    \n","    for z in range(len_z):\n","        for y in range(len_y):\n","            for x in range(len_x):\n","                if check(visited, z, y, x):\n","                    bbox = BFS(z, y, x)\n","                    if bbox:\n","                        print(f\"BBox from ({bbox[0]}, {bbox[1]}, {bbox[2]}) to ({bbox[3]}, {bbox[4]}, {bbox[5]})\")\n","                    else:\n","                        print(\"No object found at this starting point\")\n","                    \n","    \n","\n","\n","\n","make_bbox(' ')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":751906,"sourceId":1299795,"sourceType":"datasetVersion"}],"dockerImageVersionId":30458,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
