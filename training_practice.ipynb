{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "import math\n",
    "import torch\n",
    "\n",
    "''' Replay Buffer\n",
    "'''\n",
    "N_CHANNEL, N_HIGH, N_WEIGHT = 50, 256, 256\n",
    "# ReplayMemory의 역할은 state, action, reward, next_state를 저장하는 것\n",
    "# state, action, reward, next_state를 저장해서 학습할 때 사용함.\n",
    "class ReplayMemory():\n",
    "    def __init__(self, memory_size):\n",
    "        # self.memory의 역할은 state, action, reward, next_state를 저장하는 것\n",
    "        self.memory_counter = 0\n",
    "        self.memory_size = memory_size\n",
    "        self.state_memory = torch.FloatTensor(self.memory_size, 1, N_CHANNEL, N_HIGH, N_WEIGHT)\n",
    "        self.action_memory = torch.LongTensor(self.memory_size)\n",
    "        self.reward_memory = torch.FloatTensor(self.memory_size)\n",
    "        self.state__memory = torch.FloatTensor(self.memory_size, 1, N_CHANNEL, N_HIGH, N_WEIGHT)\n",
    "\n",
    "    def store(self, s, a, r, s_):\n",
    "        # 여기를 보면 index에 맞게 \"순서대로\" 저장하는 것을 볼 수 있음.\n",
    "        index = self.memory_counter % self.memory_size\n",
    "        self.state_memory[index] = s\n",
    "        self.action_memory[index] = torch.LongTensor([a.tolist()])\n",
    "        self.reward_memory[index] = torch.FloatTensor([r])\n",
    "        self.state__memory[index] = s_\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def sample(self, size):\n",
    "        sample_index = np.random.choice(self.memory_size, size)\n",
    "        state_sample = torch.FloatTensor(size,1,  N_CHANNEL, N_HIGH, N_WEIGHT)\n",
    "        action_sample = torch.LongTensor(size, 1)\n",
    "        reward_sample = torch.FloatTensor(size, 1)\n",
    "        state__sample = torch.FloatTensor(size, 1, N_CHANNEL, N_HIGH, N_WEIGHT)\n",
    "        for index in range(sample_index.size):\n",
    "            state_sample[index] = self.state_memory[sample_index[index]]\n",
    "            action_sample[index] = self.action_memory[sample_index[index]]\n",
    "            reward_sample[index] = self.reward_memory[sample_index[index]]\n",
    "            state__sample[index] = self.state__memory[sample_index[index]]\n",
    "        return state_sample, action_sample, reward_sample, state__sample\n",
    "\n",
    "\n",
    "''' Reshape state patches to full size input 50 x 256 x 256\n",
    "'''\n",
    "# crop_reshape 함수는 3D image를 (channel, 256, 256)으로 확장시키는 함수\n",
    "def crop_reshape(img, x,y,z,w,h,d):\n",
    "    img = np.array(img)\n",
    "    new_image = []\n",
    "    image_patch = img[z:z+d, x:x+h, y:y+w]\n",
    "    for i in range(image_patch.shape[0]):\n",
    "        new_image.append(cv2.resize(image_patch[i], (256,256)))\n",
    "    new_image = np.array(new_image)\n",
    "    return torch.tensor(new_image.reshape(1,1,new_image.shape[0], new_image.shape[1], new_image.shape[2])).float()\n",
    "\n",
    "'''Compute Accuracy for Training \n",
    "'''\n",
    "\n",
    "# binary_acc함수는 y_pred와 y_test를 받아서 정확도를 계산하는 함수\n",
    "def binary_acc(y_pred, y_test):\n",
    "    #y_pred[y_pred >= 0.5] = 1 \n",
    "    #y_pred[y_pred < 0.5] = 0\n",
    "    _, y_pred = y_pred.max(1)\n",
    "    correct_results_sum = (y_pred == y_test).sum().float()\n",
    "    acc = correct_results_sum#/y_test.shape[0]\n",
    "    acc = torch.round(acc)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3Dmodels  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./src/DQN_based_Localization_figure.png\" alt=\"Description of the image\" width=\"600\" height=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d,MaxUnpool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from skimage import util\n",
    "from torchvision import transforms, models\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision\n",
    "from collections import namedtuple, deque\n",
    "import math\n",
    "\n",
    "# DQNSolver함수는 3D image를 받아서 7개의 action을 출력하는 DQN 모델을 생성하는 함수\n",
    "# DQN이란 Deep Q Network의 약자로 Q-learning을 딥러닝으로 구현한 것\n",
    "class DQNSolver(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Net with 3 conv3D layers and two linear layers\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQNSolver, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(input_shape[0], 32, kernel_size=(5,5,5), stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((2, 2, 2)),\n",
    "            nn.Conv3d(32, 64, kernel_size=(5,5,5), stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((1, 2, 2)),\n",
    "            nn.Conv3d(64, 64, kernel_size=(3,3,3), stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((2, 2, 2)),\n",
    "        )\n",
    "        \n",
    "        # conv_out_size의 역할은 conv layer를 거치고 나온 output의 size를 계산하는 것\n",
    "        # _get_conv_out에 어떤 shape이 들어가냐면, \n",
    "        # DQNSolver의 예상 input_shape의 크기가 (1,50,256,256)라면, self.conv이후의 shape은  (64, 1, 7, 7)이므로\n",
    "        # conv_out_size는 64*1*7*7 = 3136이 됨.\n",
    "        # 이걸 self.fc layer를 이용해 7개로 줄여 action을 결정하게 됨.\n",
    "        # 여기서 7개의 액션은 각각의 방향으로 움직이는 것을 의미함.\n",
    "        # 0 - up, 1- down, 2 - right, 3- left, 4- top, 5 - bottom, 6 - terminate\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_actions)\n",
    "        )\n",
    "\n",
    "    \n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "        return self.fc(conv_out)\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Net with 3 conv3D layers and two linear layers\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, num_features):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(input_shape[0], 32, kernel_size=(5,5,5), stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((2, 2, 2)),\n",
    "            nn.Conv3d(32, 64, kernel_size=(5,5,5), stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((1, 2, 2)),\n",
    "            nn.Conv3d(64, 64, kernel_size=(3,3,3), stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((2, 2, 2)),\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_features),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "        return self.fc(conv_out)\n",
    "\n",
    "# concat_\n",
    "class concat_classifier(nn.Module):\n",
    "    def __init__(self, input_shape1,input_shape2, classes):\n",
    "        super(concat_classifier, self).__init__()\n",
    "\n",
    "        input_shape = input_shape1[1] + input_shape2[1]\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_shape, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, classes),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self,x1, x2):\n",
    "        cat_out = torch.cat((x1,x2), dim = 1)\n",
    "        output = self.fc(cat_out)\n",
    "        return output\n",
    "\n",
    "\n",
    "class combine_model(nn.Module):\n",
    "    def __init__(self, model1, model2, model3):\n",
    "        super(combine_model, self).__init__()\n",
    "\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        input1 = x1\n",
    "        input2 = x2\n",
    "\n",
    "        out1 = self.model1(input1)\n",
    "        out2 = self.model2(input2)\n",
    "        pred = self.model3(out1, out2)\n",
    "\n",
    "        return pred\n",
    "\n",
    "# 우리 데이터의 input shape이 어떻게 되는지 확인해야함\n",
    "policy_model = DQNSolver((1,50,256,256), 7)\n",
    "target_model = DQNSolver((1,50,256,256), 7)\n",
    "# hippocampus는 3D shape이 50, 256, 256인 이미지를 받아서 512개의 feature로 변환\n",
    "# hippocampus란 해마를 의미함.\n",
    "classifier_hippocampus = Classifier((1,50,256,256), 512)\n",
    "# global은 3D shape이 145, 256, 256인 이미지를 받아서 1024개의 feature로 변환\n",
    "# TODO: 둘 차이가 많이 나는데 이게 맞는건지 확인\n",
    "classifier_global = Classifier((1,145,256,256), 1024)\n",
    "final_model = concat_classifier((1,512), (1, 1024), 2)\n",
    "# final_model이 2개의 feature를 받아서 2개의 class로 분류하는 모델\n",
    "# 현재의 프로젝트 맥락에서 각각은 AD, CN을 의미함.\n",
    "# 여기서 AD는 Alzheimer's Disease, CN은 Control을 의미함.\n",
    "class_model = combine_model(classifier_hippocampus, classifier_global, final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d,MaxUnpool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from skimage import util\n",
    "from torchvision import transforms, models\n",
    "from torch import optim\n",
    "\n",
    "from medpy.io import load\n",
    "import cv2\n",
    "\n",
    "''' DQN Agent\n",
    "'''\n",
    "class DQNAgent(object):\n",
    "    def __init__(self, policy_model, target_model, replay_memory):\n",
    "            self.batch_size = 100\n",
    "            self.gamma = 0.99\n",
    "            self.eps = 1\n",
    "            self.target_update = 0\n",
    "            screen_height, screen_width, screen_depth = 256, 256, 145\n",
    "            self.n_actions = 7\n",
    "            self.policy_model = policy_model\n",
    "            self.target_model = target_model\n",
    "            self.target_model.eval()\n",
    "            self.optimizer = optim.Adam(self.policy_model.parameters(), lr = 0.00009)\n",
    "            self.loss_func = torch.nn.SmoothL1Loss()#nn.MSELoss()\n",
    "            self.memory = replay_memory\n",
    "\n",
    "    ''' Compute reward with L2 distance between centers of state and gd\n",
    "    '''\n",
    "    def compute_reward(self, actual_state, prev_state, ground_truth, threshold):\n",
    "            x,y,z,w,h,d = actual_state\n",
    "            x_p,y_p,z_p,w_p,h_p,d_p = prev_state\n",
    "            x_gd, y_gd, z_gd, w_gd, h_gd, d_gd = ground_truth\n",
    "\n",
    "            center = np.array([(x+w)/2,(y+h)/2, (z+d)/2])\n",
    "            center_gd = np.array([(x_gd + w_gd)/2,(y_gd + h_gd)/2, (z_gd + d_gd)/2])\n",
    "            center_p = np.array([(x_p + w_p)/2,(y_p + h_p )/2, (z_p + d_p)/2])\n",
    "            dist_l2 = np.linalg.norm(center - center_gd)\n",
    "            dist_l2_p = np.linalg.norm(center_p - center_gd)\n",
    "\n",
    "            if dist_l2 < threshold:\n",
    "                game = \"END\"\n",
    "                reward = 100\n",
    "                return game, reward\n",
    "            else:\n",
    "                game = \"continue\"\n",
    "                reward = min(1, -dist_l2) #dist_l2 - dist_l2_p #\n",
    "                return game, reward\n",
    "\n",
    "    ''' 0 - up, 1- down, 2 - right, 3- left, 4- top, 5 - bottom, 6 - terminate\n",
    "    '''\n",
    "    # def next_state(self, prev_state, actn, step):\n",
    "    #     # TODO: 일단 우리 data는 240x240x155이므로 그에 맞게 코드를 수정하던가 우리의 데이터를 interpolation해야할 듯 함.\n",
    "    #     # 근데 이미 interpolation하는 코드가 있어서, 그걸 사용하면 될 듯함.\n",
    "    #         x,y,z,w,h,d = prev_state\n",
    "    #         # max_x:가 왜 255인지 모르겠음\n",
    "    #         max_x = 255\n",
    "    #         max_y = 255\n",
    "    #         max_z = 140\n",
    "    #         min_x = 0\n",
    "    #         min_y = 0\n",
    "    #         min_z = 0\n",
    "\n",
    "    #         if actn == 0:\n",
    "    #             if x + w + step >= 255:\n",
    "    #                 x = 100\n",
    "    #             else:\n",
    "    #                 x = x + step\n",
    "    #         elif actn == 1:\n",
    "    #             if x - step <= 0:\n",
    "    #                 x = 100\n",
    "    #             else:\n",
    "    #                 x = x - step\n",
    "    #         elif actn == 2:\n",
    "    #             if y + h + step >= 255:\n",
    "    #                 y = 100\n",
    "    #             else:\n",
    "    #                 y = y + step\n",
    "    #         elif actn == 3:\n",
    "    #             if y - step <= 0:\n",
    "    #                 y = 100\n",
    "    #             else:\n",
    "    #                 y = y - step\n",
    "    #         elif actn == 4:\n",
    "    #             if z + d + step >= 144 :\n",
    "    #                 z = 50\n",
    "    #             else:\n",
    "    #                 z = z + step\n",
    "    #         elif actn == 5:\n",
    "    #             if z - step <= 0:\n",
    "    #                 z = 50\n",
    "    #             else:\n",
    "    #                 z = z - step\n",
    "\n",
    "    #         return [int(x),int(y),int(z),int(w),int(h),int(d)]\n",
    "    def next_state(self, prev_state, actn, step):\n",
    "        # Constants for boundaries\n",
    "        max_bounds = {'x': 255, 'y': 255, 'z': 140}\n",
    "        min_bounds = {'x': 0, 'y': 0, 'z': 0}\n",
    "        \n",
    "        x, y, z, w, h, d = prev_state\n",
    "\n",
    "        # Action mapping\n",
    "        actions = {\n",
    "            0: ('x', step, max_bounds['x'], 100),\n",
    "            1: ('x', -step, min_bounds['x'], 100),\n",
    "            2: ('y', step, max_bounds['y'], 100),\n",
    "            3: ('y', -step, min_bounds['y'], 100),\n",
    "            4: ('z', step, max_bounds['z'], 50),\n",
    "            5: ('z', -step, min_bounds['z'], 50)\n",
    "        }\n",
    "        \n",
    "        # Get the corresponding parameters for the action\n",
    "        axis, movement, bound, reset_value = actions.get(actn, (None, 0, 0, 0))\n",
    "        \n",
    "        # Apply the movement and boundary checks\n",
    "        if axis == 'x':\n",
    "            x = self.update_coordinate(x, movement, bound, reset_value)\n",
    "        elif axis == 'y':\n",
    "            y = self.update_coordinate(y, movement, bound, reset_value)\n",
    "        elif axis == 'z':\n",
    "            z = self.update_coordinate(z, movement, bound, reset_value)\n",
    "        \n",
    "        return [int(x),int(y),int(z),int(w),int(h),int(d)]\n",
    "\n",
    "    def update_coordinate(self, coord, movement, bound, reset_value):\n",
    "        new_coord = coord + movement\n",
    "        if movement > 0:  # Moving forward\n",
    "            if new_coord >= bound:\n",
    "                return reset_value\n",
    "        else:  # Moving backward\n",
    "            if new_coord <= bound:\n",
    "                return reset_value\n",
    "        return new_coord\n",
    "\n",
    "\n",
    "    ''' Start with high eps then reduce eps, if game = END then action should be 6\n",
    "    '''\n",
    "    # epsilon-greedy 방법을 이용해서 action을 선택하는 함수\n",
    "    def select_action(self, state, game, eps ):\n",
    "            actn = 6\n",
    "            if game == \"continue\":\n",
    "                sample = random.random()\n",
    "                if sample < eps:\n",
    "                    actn = np.asarray(random.randrange(6))\n",
    "\n",
    "                else:\n",
    "                    out = self.policy_model(state)\n",
    "                    _, actn = torch.max(out.data, 1)\n",
    "\n",
    "                actn = np.array(actn)\n",
    "                return actn\n",
    "            else:\n",
    "                actn = np.array(actn)\n",
    "                return actn\n",
    "\n",
    "    def select_action_test(self, state):\n",
    "        out = self.target_model(state)\n",
    "        _, actn = torch.max(out.data,1)\n",
    "        return actn\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "            self.memory.store(s, a, r, s_)\n",
    "\n",
    "    ''' Optimize model with replay memory\n",
    "    '''\n",
    "\n",
    "    def optimize(self, counter):\n",
    "\n",
    "            if self.target_update > counter:\n",
    "                self.target_model.load_state_dict(self.policy_model.state_dict())\n",
    "                self.target_update = 0\n",
    "                #print(\"Updating Target Net\")\n",
    "\n",
    "            self.target_update += 1\n",
    "\n",
    "\n",
    "            s_s, a_s, r_s, s__s = self.memory.sample(self.batch_size)\n",
    "\n",
    "            q_eval = self.policy_model(s_s).gather(1, a_s)\n",
    "            q_next = self.target_model(s__s).detach()\n",
    "            q_target = r_s + self.gamma * q_next.max(1)[0].view(self.batch_size, 1)\n",
    "            loss = self.loss_func(q_eval, q_target)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            return loss\n",
    "\n",
    "my_dqn = DQNAgent(policy_model, target_model, ReplayMemory(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Data Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../archive_BraTS2022'\n",
    "TRAIN_PATH = f'{DATA_PATH}/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n",
    "TEST_PATH = f'{DATA_PATH}/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n",
    "DATA_TYPES = ['flair', 't1', 't1ce', 't2', 'seg']\n",
    "N_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_brats_data...\n",
      "369 369 1845  - len(files_path), len(mask_paths), len(unique_id)\n",
      "['../archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_082/BraTS20_Training_082_t1.nii', '../archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_244/BraTS20_Training_244_t1.nii'] ['../archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_082/BraTS20_Training_082_seg.nii', '../archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_244/BraTS20_Training_244_seg.nii'] ['82', '82']  - files_path, mask_paths, unique_id\n",
      "load_brats_data done.\n",
      "compute_brats_masks...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb0ebee6f02472ea9f11adf0d85f41e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/369 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 97\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m marks\n\u001b[1;32m     96\u001b[0m all_files_id, mask_paths, unique_id \u001b[38;5;241m=\u001b[39m load_brats_data(TRAIN_PATH)\n\u001b[0;32m---> 97\u001b[0m sliced_masks \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_brats_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m sliced_markers \u001b[38;5;241m=\u001b[39m brats_markers(sliced_masks)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mprint\u001b[39m(sliced_masks[:\u001b[38;5;241m2\u001b[39m], sliced_markers[:\u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - sliced_masks, sliced_markers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [5], line 31\u001b[0m, in \u001b[0;36mcompute_brats_masks\u001b[0;34m(mask_paths, var1, var2)\u001b[0m\n\u001b[1;32m     29\u001b[0m all_masks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mask_path \u001b[38;5;129;01min\u001b[39;00m tqdm(mask_paths):\n\u001b[0;32m---> 31\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[43mnib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_fdata()  \u001b[38;5;66;03m# 마스크 데이터 로드\u001b[39;00m\n\u001b[1;32m     32\u001b[0m     dummy_var \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mmin\u001b[39m(var2, mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/site-packages/nibabel/loadsave.py:100\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Check file exists and is not empty\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     stat_result \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or no access: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from glob import glob\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def load_brats_data(path):\n",
    "    print('load_brats_data...')\n",
    "    files_path = []\n",
    "    mask_paths = []\n",
    "    unique_id = []\n",
    "    for file_path in glob(f'{path}/*/*.nii'):\n",
    "        # t1 파일만 처리\n",
    "        if re.search(r\"_t1(?=\\.)\", file_path):\n",
    "            files_path.append(file_path)\n",
    "        # seg 파일만 처리\n",
    "        if \"seg\" in file_path:  # segmentation mask file\n",
    "            mask_paths.append(file_path)\n",
    "        unique_id.append(str(int(file_path.split('_')[-2])))\n",
    "    print(len(files_path), len(mask_paths), len(unique_id), \" - len(files_path), len(mask_paths), len(unique_id)\")\n",
    "    print(files_path[:2], mask_paths[:2], unique_id[:2], \" - files_path, mask_paths, unique_id\")\n",
    "    print(\"load_brats_data done.\")\n",
    "    return sorted(files_path), sorted(mask_paths), sorted(list(set(unique_id)), key=lambda x: int(x))\n",
    "\n",
    "var1 = 0\n",
    "var2 = 150\n",
    "def compute_brats_masks(mask_paths, var1, var2):\n",
    "    print('compute_brats_masks...')\n",
    "    all_masks = []\n",
    "    for mask_path in tqdm(mask_paths):\n",
    "        mask = nib.load(mask_path).get_fdata()  # 마스크 데이터 로드\n",
    "        dummy_var = []\n",
    "        for j in range(min(var2, mask.shape[-1])):\n",
    "            if j <= var2:  # 주어진 범위 내의 슬라이스만 처리\n",
    "                msk = mask[:, :, j] / mask.max() * 255  # 슬라이스 정규화 및 스케일링(0 ~ 1)\n",
    "                # msk = cv2.resize(msk, (256, 256))  # 이미지 크기 조정\n",
    "                _, bw_img = cv2.threshold(msk.astype(np.uint8), 10, 255, cv2.THRESH_OTSU)  # 이진화\n",
    "                contours, _ = cv2.findContours(bw_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 컨투어 찾기\n",
    "                \n",
    "                # 가장 큰 컨투어 찾기\n",
    "                max_area = 0\n",
    "                max_rect = (0, 0, 0, 0)\n",
    "                for contour in contours:\n",
    "                    rect = cv2.boundingRect(contour)\n",
    "                    area = rect[2] * rect[3]  # rectangle의 넓이 (width * height)\n",
    "                    if area > max_area:\n",
    "                        max_area = area\n",
    "                        max_rect = rect\n",
    "                \n",
    "                # 가장 큰 컨투어의 사각형 정보 저장\n",
    "                if max_area > 0:\n",
    "                    dummy_var.append([j, max_rect])\n",
    "                else:\n",
    "                    dummy_rect = [0, 0, 0, 0]  # 컨투어가 없을 경우\n",
    "                    dummy_var.append([j, dummy_rect])\n",
    "        all_masks.append(dummy_var)\n",
    "    \n",
    "    # np_all_masks는 단순히 shape을 위해 만든 것\n",
    "    np_all_masks = np.array(all_masks, dtype=object)\n",
    "    print(np_all_masks.shape, \" - np_all_masks.shape\")\n",
    "    print(\"compute_brats_masks done.\")\n",
    "    return all_masks\n",
    "\n",
    "\n",
    "def brats_markers(slices_mask):\n",
    "    print('brats_markers...')\n",
    "    marks = []\n",
    "    for i in tqdm(range(len(slices_mask))):\n",
    "        x_min = []\n",
    "        y_min = []\n",
    "        w_max = []\n",
    "        h_max = []\n",
    "        indx_diff = []\n",
    "        for j in range(len(slices_mask[i])):\n",
    "            x_min.append(slices_mask[i][j][1][0])\n",
    "            y_min.append(slices_mask[i][j][1][1])\n",
    "            w_max.append(slices_mask[i][j][1][2])\n",
    "            h_max.append(slices_mask[i][j][1][3])\n",
    "\n",
    "            if slices_mask[i][j][1][0] != 0:\n",
    "                indx_diff.append(slices_mask[i][j][0])\n",
    "        x_min = np.array(x_min)\n",
    "        y_min = np.array(y_min)\n",
    "        x_mn = np.min(x_min[np.nonzero(x_min)])\n",
    "        y_mn = np.min(y_min[np.nonzero(y_min)])\n",
    "        w_mx = np.array(w_max).max()\n",
    "        h_mx = np.array(h_max).max()\n",
    "        dim = [x_mn, y_mn, w_mx, h_mx]\n",
    "        d_mx = indx_diff[-1] - indx_diff[0]\n",
    "        z_mn = indx_diff[0]\n",
    "        marks.append([x_mn, y_mn, z_mn, w_mx, h_mx, d_mx])\n",
    "    print(marks[:2], \" - marks[:2]\")\n",
    "    print(\"brats_markers done.\")\n",
    "    return marks\n",
    "\n",
    "all_files_id, mask_paths, unique_id = load_brats_data(TRAIN_PATH)\n",
    "sliced_masks = compute_brats_masks(mask_paths, var1, var2)\n",
    "sliced_markers = brats_markers(sliced_masks)\n",
    "print(sliced_masks[:2], sliced_markers[:2], \" - sliced_masks, sliced_markers\")\n",
    "# # Create labels (example: 1 for tumor presence, 0 for no tumor)\n",
    "# labels = np.ones((len(sliced_markers), 1))  # Assuming all masks are tumors\n",
    "\n",
    "# label_data = np.hstack([sliced_markers, labels])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data_Prep - Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/choihanjun/Library/Mobile Documents/com~apple~CloudDocs/Downloads/2024-1/[강화학습]/Project/RLovyou/training_practice.ipynb 셀 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/choihanjun/Library/Mobile%20Documents/com~apple~CloudDocs/Downloads/2024-1/%5B%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%5D/Project/RLovyou/training_practice.ipynb#W6sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m labels_ad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((\u001b[39mlen\u001b[39m(sliced_markers_ad),\u001b[39m1\u001b[39m))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/choihanjun/Library/Mobile%20Documents/com~apple~CloudDocs/Downloads/2024-1/%5B%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%5D/Project/RLovyou/training_practice.ipynb#W6sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m labels_cn \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(sliced_markers_cn),\u001b[39m1\u001b[39m))\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/choihanjun/Library/Mobile%20Documents/com~apple~CloudDocs/Downloads/2024-1/%5B%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%5D/Project/RLovyou/training_practice.ipynb#W6sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m label_cn \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mhstack([sliced_markers_cn, labels_cn])\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/choihanjun/Library/Mobile%20Documents/com~apple~CloudDocs/Downloads/2024-1/%5B%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%5D/Project/RLovyou/training_practice.ipynb#W6sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m label_ad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack([sliced_markers_ad, labels_ad])\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/choihanjun/Library/Mobile%20Documents/com~apple~CloudDocs/Downloads/2024-1/%5B%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%5D/Project/RLovyou/training_practice.ipynb#W6sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mdata_cleaning_concat\u001b[39;00m():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/site-packages/numpy/core/shape_base.py:357\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m arrs \u001b[39mand\u001b[39;00m arrs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n\u001b[1;32m    358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39mconcatenate(arrs, \u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mdtype, casting\u001b[39m=\u001b[39mcasting)\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import fnmatch\n",
    "import os\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from medpy.io import load\n",
    "import cv2\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "''' Read files for AD and CN\n",
    "'''\n",
    "\n",
    "# def mask_load(path):\n",
    "    # files_id = []\n",
    "    # mask = []\n",
    "    # unique_id = []\n",
    "    # for root, folder, file in os.walk(os.path.abspath(path)):\n",
    "    #     for masks in fnmatch.filter(file,\"*.nii\"):\n",
    "    #         y = os.path.join(root, masks).rsplit(\"\\\\\")[6]\n",
    "    #         uid = os.path.join(root, masks).rsplit(\"\\\\\")[8]\n",
    "    #         mask.append(os.path.join(root, masks))\n",
    "    #         files_id.append(y)\n",
    "    #         unique_id.append(uid)\n",
    "    # return files_id, mask, unique_id\n",
    "\n",
    "# path_ad = \"Path to AD\\\\ADNI\"\n",
    "# all_files_ad_id, mask_ad, ad_unique_id = mask_load(path_ad)\n",
    "\n",
    "# path_cn = \"Path to \\\\CN\\\\ADNI\"\n",
    "# all_files_cn_id, mask_cn, cn_unique_id = mask_load(path_cn)\n",
    "\n",
    "\n",
    "brats_file_paths, brats_mask_paths, brats_unique_id = load_brats_data(TRAIN_PATH)\n",
    "#MP-RAGE_, SAG_MP-RAGE, MP-RAGE-, MPRAGE, MPRAGE_, MP-RAGE\n",
    "\n",
    "# def data_load(path, file_id, unique_id):\n",
    "#   file_path = []\n",
    "#   f_path = []\n",
    "#   for root, folder, file in os.walk(os.path.abspath(path)):\n",
    "#     f_path = []\n",
    "#     for filename in fnmatch.filter(file, \"*.dcm\" ):\n",
    "#       id1 = os.path.join(root, filename).rsplit(\"\\\\\")[6]\n",
    "#       if id1 in file_id:\n",
    "#           id2 = os.path.join(root, filename).rsplit(\"\\\\\")[8]\n",
    "#           if id2 in unique_id:\n",
    "#               x = os.path.join(root, filename).rsplit(\"\\\\\")[7]\n",
    "#               if (x == \"MP-RAGE_\" or x == \"SAG_MP-RAGE\" or x == \"MP-RAGE-\" or\n",
    "#                    x == \"MPRAGE\" or x == \"MPRAGE_\" or x == \"MP-RAGE\") :\n",
    "#                        f_path.append(os.path.join(root, filename))\n",
    "\n",
    "#     if len(f_path) != 0:\n",
    "#         file_path.append(f_path)\n",
    "#   return file_path\n",
    "\n",
    "# all_files_ad = data_load(path_ad, all_files_ad_id, ad_unique_id )\n",
    "\n",
    "# def data_load_cn(path, file_id, unique_id):\n",
    "#   file_path = []\n",
    "#   f_path = []\n",
    "#   for root, folder, file in os.walk(os.path.abspath(path)):\n",
    "#     f_path = []\n",
    "#     for filename in fnmatch.filter(file, \"*.dcm\" ):\n",
    "#       id1 = os.path.join(root, filename).rsplit(\"\\\\\")[6]\n",
    "#       if id1 in file_id:\n",
    "#           id2 = os.path.join(root, filename).rsplit(\"\\\\\")[8]\n",
    "#           if id2 in unique_id:\n",
    "#               x = os.path.join(root, filename).rsplit(\"\\\\\")[7]\n",
    "#               if ( x == \"MP-RAGE_\" or x == \"MP-RAGE-\" or x == \"MPRAGE\" or\n",
    "#                    x == \"SAG_MP-RAGE_\" or x == \"MPRAGE_\" or x == \"MP_RAGE\" or\n",
    "#                    x == \"MP-RAGE\" or x == \"MP-RAGE_\" or x == \"MP-RAGE__SERIES_2_\" or\n",
    "#                    x == \"SAG_MP-RAGE\") :\n",
    "#                        f_path.append(os.path.join(root, filename))\n",
    "\n",
    "#     if len(f_path) != 0:\n",
    "#         file_path.append(f_path)\n",
    "#   return file_path\n",
    "\n",
    "# all_files_cn = data_load_cn(path_cn, all_files_cn_id, cn_unique_id)\n",
    "\n",
    "''' Choose slices 25 - 125\n",
    "'''\n",
    "# 원래는 slice마다 image가 있어서, 이걸 전부 붙이는 과정이 있었는 듯 함.\n",
    "var1 = 15\n",
    "var2 = 159\n",
    "# def slice_select(var1, var2, file_path):\n",
    "#     new_filepath = []\n",
    "#     for i in range(len(file_path)):\n",
    "#         dummy_var = []\n",
    "#         for j in range(len(file_path[i])):\n",
    "#             if j>=var1 and j<= var2:\n",
    "#                 dummy_var.append(file_path[i][j])\n",
    "#         new_filepath.append(dummy_var)\n",
    "#     return new_filepath\n",
    "\n",
    "# sliced_all_files_cn = slice_select(var1, var2, all_files_cn)\n",
    "# sliced_all_files_ad = slice_select(var1, var2, all_files_ad)\n",
    "\n",
    "''' mask selection\n",
    "'''\n",
    "\n",
    "def compute_all_masks(var1, var2, file):\n",
    "    all_masks = []\n",
    "    for i in range(len(file)):\n",
    "        mask1,_ = load(file[i])\n",
    "        dummy_var = []\n",
    "        for j in range(mask1.shape[0]):\n",
    "            if j >= var1 and j <= var2:\n",
    "                msk = 255*mask1[j]/mask1[j].max()\n",
    "                msk = cv2.resize(msk, (256,256))\n",
    "                _, bw_img = cv2.threshold(msk.astype(np.uint8), 10, 255, cv2.THRESH_OTSU)\n",
    "                # _, bw_img = cv2.threshold(masks[indx_mx], 127, 255, cv2.THRESH_BINARY)\n",
    "                contours,_ = cv2.findContours(bw_img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "                if len(contours) != 0:\n",
    "                    # TODO: contours에서 가장 큰 것을 rect에 저장되도록 코드 수정.\n",
    "                    # 그래서 2D image마다 contours를 찾아서 저장하고 있음, 이를 수정해야함.\n",
    "                    rect =  cv2.boundingRect(contours[0])\n",
    "                    dummy_var.append([j, rect])\n",
    "                else:\n",
    "                    dummy_rect = [0,0,0,0]\n",
    "                    dummy_var.append([j, dummy_rect])\n",
    "\n",
    "        all_masks.append(dummy_var)\n",
    "    return all_masks\n",
    "\n",
    "def compute_all_brats_masks(var1, var2, file):\n",
    "    all_masks = []\n",
    "    for i in range(len(file)):\n",
    "        mask1,_ = load(file[i])\n",
    "        dummy_var = []\n",
    "        for j in range(mask1.shape[0]):\n",
    "            if j >= var1 and j <= var2:\n",
    "                msk = 255*mask1[j]/mask1[j].max()\n",
    "                msk = cv2.resize(msk, (256,256))\n",
    "                _, bw_img = cv2.threshold(msk.astype(np.uint8), 10, 255, cv2.THRESH_OTSU)\n",
    "                # _, bw_img = cv2.threshold(masks[indx_mx], 127, 255, cv2.THRESH_BINARY)\n",
    "                contours,_ = cv2.findContours(bw_img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "                if len(contours) != 0:\n",
    "                    # TODO: contours에서 가장 큰 것을 rect에 저장되도록 코드 수정.\n",
    "                    # 그래서 2D image마다 contours를 찾아서 저장하고 있음, 이를 수정해야함.\n",
    "                    rect =  cv2.boundingRect(contours[0])\n",
    "                    dummy_var.append([j, rect])\n",
    "                else:\n",
    "                    dummy_rect = [0,0,0,0]\n",
    "                    dummy_var.append([j, dummy_rect])\n",
    "\n",
    "        all_masks.append(dummy_var)\n",
    "    return all_masks\n",
    "\n",
    "\n",
    "# mask_cn의 예상 입력은 file_paths이다. \n",
    "# sliced_masks_cn = compute_all_masks(var1, var2, mask_cn)\n",
    "# sliced_masks_ad = compute_all_masks(var1, var2, mask_ad)\n",
    "\n",
    "\n",
    "brats_sliced_masks = compute_all_masks(var1, var2, brats_mask_paths)\n",
    "\n",
    "''' Select mask dimension and markers for Hippocampus region\n",
    "'''\n",
    "def markers(slices_mask):\n",
    "    marks = []\n",
    "    for i in range(len(slices_mask)):\n",
    "        x_min = []\n",
    "        y_min = []\n",
    "        w_max = []\n",
    "        h_max = []\n",
    "        z_mn = 0\n",
    "        indx_diff = []\n",
    "        for j in range(len(slices_mask[i])):\n",
    "            x_min.append(slices_mask[i][j][1][0])\n",
    "            y_min.append(slices_mask[i][j][1][1])\n",
    "            w_max.append(slices_mask[i][j][1][2])\n",
    "            h_max.append(slices_mask[i][j][1][3])\n",
    "\n",
    "            if slices_mask[i][j][1][0] != 0:\n",
    "                indx_diff.append(slices_mask[i][j][0])\n",
    "        x_min = np.array(x_min)\n",
    "        y_min = np.array(y_min)\n",
    "        x_mn = np.min(x_min[np.nonzero(x_min)])\n",
    "        y_mn = np.min(y_min[np.nonzero(y_min)])\n",
    "        w_mx = np.array(w_max).max()\n",
    "        h_mx = np.array(h_max).max()\n",
    "        dim = [x_mn, y_mn, w_mx, h_mx]\n",
    "        # print(dim)\n",
    "        d_mx = indx_diff[-1] - indx_diff[0]\n",
    "        # print(diff)\n",
    "        z_mn = indx_diff[0]\n",
    "        marks.append([x_mn, y_mn, z_mn, w_mx, h_mx , d_mx])\n",
    "    return marks\n",
    "\n",
    "sliced_markers_cn = markers(sliced_masks_cn)\n",
    "sliced_markers_ad = markers(sliced_masks_ad)\n",
    "\n",
    "''' Concat labels 1 - AD,  0 -  CN\n",
    "'''\n",
    "labels_ad = np.ones((len(sliced_markers_ad),1))\n",
    "labels_cn = np.zeros((len(sliced_markers_cn),1))\n",
    "\n",
    "label_cn = np.hstack([sliced_markers_cn, labels_cn])\n",
    "label_ad = np.hstack([sliced_markers_ad, labels_ad])\n",
    "\n",
    "\n",
    "class data_cleaning_concat():\n",
    "    def __init__(self, data1, data2, label1, label2):\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        self.label1 = label1\n",
    "        self.label2 = label2\n",
    "\n",
    "    def _index_values(self, dataset):\n",
    "        index = []\n",
    "        for i in range(len(dataset)):\n",
    "            if len(dataset[i]) < 145:\n",
    "                index.append(i)\n",
    "        return index\n",
    "\n",
    "    def _pop_list(self, dataset, label, index):\n",
    "        for i in range(len(index)):\n",
    "            dataset.pop(index[i])\n",
    "            label.pop(index[i])\n",
    "        return dataset, label\n",
    "\n",
    "    def files_concat(self):\n",
    "        concat_data = []\n",
    "        concat_label = []\n",
    "\n",
    "        data1_ , label1_ = self._pop_list(self.data1, self.label1, self._index_values(self.data1))\n",
    "        data2_ , label2_ = self._pop_list(self.data2, self.label2, self._index_values(self.data2))\n",
    "\n",
    "        for i in range(len(data1_)):\n",
    "            concat_data.append(data1_[i])\n",
    "            concat_label.append(label1_[i])\n",
    "\n",
    "        for j in range(len(data2_)):\n",
    "            concat_data.append(data2_[j])\n",
    "            concat_label.append(label2_[j])\n",
    "\n",
    "        return shuffle(concat_data, concat_label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_clean = data_cleaning_concat(sliced_all_files_ad, sliced_all_files_cn,\n",
    "                                                list(label_ad) , list(label_cn))\n",
    "total_data , total_label = data_clean.files_concat()\n",
    "\n",
    "def cross_valid_splits(data, label, fold):\n",
    "    fold_train = []\n",
    "    fold_test = []\n",
    "    fold_ytrain = []\n",
    "    fold_ytest = []\n",
    "\n",
    "    indxs1 = int(1*len(data)/5)\n",
    "    indxs2 = int(2*len(data)/5)\n",
    "    indxs3 = int(3*len(data)/5)\n",
    "    indxs4 = int(4*len(data)/5)\n",
    "    indxs5 = int(5*len(data)/5)\n",
    "\n",
    "    rn_trn = []\n",
    "    rn_tst = []\n",
    "    if fold == 1:\n",
    "        for i in range(0, indxs4):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "\n",
    "        for j in range(indxs4, indxs5):\n",
    "            fold_test.append(data[j])\n",
    "            fold_ytest.append(label[j])\n",
    "\n",
    "    elif fold == 2:\n",
    "        for i in range(0, indxs3):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "        for i in range(indxs4,indxs5):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "\n",
    "\n",
    "        for j in range(indxs3, indxs4):\n",
    "            fold_test.append(data[j])\n",
    "            fold_ytest.append(label[j])\n",
    "\n",
    "    elif fold == 3:\n",
    "        for i in range(0, indxs2):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "        for i in range(indxs3,indxs5):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "\n",
    "\n",
    "        for j in range(indxs2, indxs3):\n",
    "            fold_test.append(data[j])\n",
    "            fold_ytest.append(label[j])\n",
    "\n",
    "\n",
    "    elif fold == 4:\n",
    "        for i in range(0, indxs1):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "        for i in range(indxs2,indxs5):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "\n",
    "\n",
    "        for j in range(indxs1, indxs2):\n",
    "            fold_test.append(data[j])\n",
    "            fold_ytest.append(label[j])\n",
    "\n",
    "\n",
    "    elif fold == 5:\n",
    "        for i in range(indxs1, indxs5):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "\n",
    "        for j in range(0, indxs1):\n",
    "            fold_test.append(data[j])\n",
    "            fold_ytest.append(label[j])\n",
    "\n",
    "\n",
    "    return fold_train, fold_test, np.array(fold_ytrain), np.array(fold_ytest)\n",
    "\n",
    "\n",
    "f_train1, f_test1, f_ytrain1, f_ytest1 = cross_valid_splits(total_data, total_label,1)\n",
    "\n",
    "f_train2, f_test2, f_ytrain2, f_ytest2 = cross_valid_splits(total_data, total_label,2)\n",
    "\n",
    "f_train3, f_test3, f_ytrain3, f_ytest3 = cross_valid_splits(total_data, total_label,3)\n",
    "\n",
    "f_train4, f_test4, f_ytrain4, f_ytest4 = cross_valid_splits(total_data, total_label,4)\n",
    "\n",
    "f_train5, f_test5, f_ytrain5, f_ytest5 = cross_valid_splits(total_data, total_label,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data_Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_brats_data...\n",
      "369 369 1845  - len(files_path), len(mask_paths), len(unique_id)\n",
      "['../archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_082/BraTS20_Training_082_t1.nii', '../archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_244/BraTS20_Training_244_t1.nii'] ['../archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_082/BraTS20_Training_082_seg.nii', '../archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_244/BraTS20_Training_244_seg.nii'] ['82', '82']  - files_path, mask_paths, unique_id\n",
      "load_brats_data done.\n",
      "compute_brats_masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0, [0, 0, 0, 0]], [1, [0, 0, 0, 0]], [2, [0, 0, 0, 0]], [3, [0, 0, 0, 0]], [4, [0, 0, 0, 0]], [5, [0, 0, 0, 0]], [6, [0, 0, 0, 0]], [7, [0, 0, 0, 0]], [8, [0, 0, 0, 0]], [9, [0, 0, 0, 0]], [10, [0, 0, 0, 0]], [11, [0, 0, 0, 0]], [12, [0, 0, 0, 0]], [13, [0, 0, 0, 0]], [14, [0, 0, 0, 0]], [15, [0, 0, 0, 0]], [16, [0, 0, 0, 0]], [17, [0, 0, 0, 0]], [18, [0, 0, 0, 0]], [19, [0, 0, 0, 0]], [20, [0, 0, 0, 0]], [21, [0, 0, 0, 0]], [22, [0, 0, 0, 0]], [23, [0, 0, 0, 0]], [24, [0, 0, 0, 0]], [25, [0, 0, 0, 0]], [26, [0, 0, 0, 0]], [27, [0, 0, 0, 0]], [28, [0, 0, 0, 0]], [29, [0, 0, 0, 0]], [30, (107, 93, 2, 2)], [31, (100, 88, 11, 9)], [32, (98, 80, 19, 18)], [33, (98, 80, 20, 20)], [34, (96, 74, 22, 26)], [35, (96, 74, 23, 26)], [36, (95, 73, 26, 27)], [37, (91, 73, 32, 28)], [38, (90, 72, 35, 29)], [39, (89, 71, 36, 29)], [40, (89, 71, 37, 29)], [41, (89, 71, 37, 29)], [42, (85, 71, 43, 32)], [43, (85, 71, 44, 32)], [44, (85, 70, 47, 33)], [45, (85, 70, 47, 33)], [46, (85, 70, 48, 37)], [47, (84, 70, 49, 45)], [48, (85, 70, 58, 46)], [49, (85, 63, 61, 54)], [50, (85, 62, 61, 55)], [51, (86, 60, 60, 58)], [52, (86, 60, 61, 61)], [53, (86, 60, 68, 70)], [54, (86, 58, 74, 69)], [55, (87, 58, 73, 68)], [56, (87, 58, 75, 68)], [57, (88, 57, 75, 69)], [58, (88, 57, 75, 78)], [59, (88, 53, 80, 85)], [60, (89, 53, 80, 85)], [61, (89, 52, 81, 86)], [62, (89, 51, 82, 87)], [63, (89, 51, 82, 86)], [64, (87, 51, 85, 86)], [65, (85, 51, 98, 86)], [66, (82, 51, 102, 86)], [67, (81, 51, 104, 86)], [68, (81, 51, 105, 86)], [69, (80, 52, 106, 85)], [70, (80, 52, 106, 85)], [71, (80, 52, 107, 85)], [72, (79, 52, 108, 85)], [73, (78, 53, 108, 82)], [74, (78, 57, 107, 78)], [75, (78, 57, 107, 78)], [76, (78, 58, 107, 77)], [77, (78, 58, 105, 76)], [78, (77, 58, 105, 76)], [79, (77, 58, 104, 76)], [80, (77, 58, 103, 76)], [81, (77, 58, 102, 77)], [82, (77, 58, 102, 76)], [83, (77, 59, 101, 75)], [84, (77, 59, 100, 74)], [85, (78, 58, 96, 72)], [86, (78, 58, 96, 72)], [87, (78, 58, 95, 73)], [88, (78, 59, 94, 78)], [89, (78, 59, 94, 72)], [90, (78, 59, 93, 72)], [91, (79, 60, 92, 72)], [92, (80, 62, 91, 71)], [93, (80, 63, 91, 70)], [94, (80, 63, 91, 70)], [95, (81, 64, 89, 69)], [96, (81, 64, 88, 59)], [97, (88, 71, 80, 52)], [98, (91, 72, 76, 51)], [99, (92, 72, 75, 49)], [100, (92, 72, 74, 47)], [101, (93, 73, 72, 43)], [102, (94, 77, 70, 37)], [103, (99, 79, 63, 35)], [104, (100, 80, 62, 33)], [105, (102, 85, 54, 27)], [106, (104, 86, 51, 26)], [107, (105, 86, 46, 25)], [108, (108, 87, 31, 21)], [109, (119, 89, 18, 15)], [110, (120, 89, 17, 15)], [111, (122, 90, 12, 14)], [112, (127, 100, 4, 3)], [113, [0, 0, 0, 0]], [114, [0, 0, 0, 0]], [115, [0, 0, 0, 0]], [116, [0, 0, 0, 0]], [117, [0, 0, 0, 0]], [118, [0, 0, 0, 0]], [119, [0, 0, 0, 0]], [120, [0, 0, 0, 0]], [121, [0, 0, 0, 0]], [122, [0, 0, 0, 0]], [123, [0, 0, 0, 0]], [124, [0, 0, 0, 0]], [125, [0, 0, 0, 0]], [126, [0, 0, 0, 0]], [127, [0, 0, 0, 0]], [128, [0, 0, 0, 0]], [129, [0, 0, 0, 0]], [130, [0, 0, 0, 0]], [131, [0, 0, 0, 0]], [132, [0, 0, 0, 0]], [133, [0, 0, 0, 0]], [134, [0, 0, 0, 0]], [135, [0, 0, 0, 0]], [136, [0, 0, 0, 0]], [137, [0, 0, 0, 0]], [138, [0, 0, 0, 0]], [139, [0, 0, 0, 0]], [140, [0, 0, 0, 0]], [141, [0, 0, 0, 0]], [142, [0, 0, 0, 0]], [143, [0, 0, 0, 0]], [144, [0, 0, 0, 0]], [145, [0, 0, 0, 0]], [146, [0, 0, 0, 0]], [147, [0, 0, 0, 0]], [148, [0, 0, 0, 0]], [149, [0, 0, 0, 0]]], [[0, [0, 0, 0, 0]], [1, [0, 0, 0, 0]], [2, [0, 0, 0, 0]], [3, [0, 0, 0, 0]], [4, [0, 0, 0, 0]], [5, [0, 0, 0, 0]], [6, [0, 0, 0, 0]], [7, [0, 0, 0, 0]], [8, [0, 0, 0, 0]], [9, [0, 0, 0, 0]], [10, [0, 0, 0, 0]], [11, [0, 0, 0, 0]], [12, [0, 0, 0, 0]], [13, [0, 0, 0, 0]], [14, [0, 0, 0, 0]], [15, [0, 0, 0, 0]], [16, [0, 0, 0, 0]], [17, [0, 0, 0, 0]], [18, [0, 0, 0, 0]], [19, [0, 0, 0, 0]], [20, [0, 0, 0, 0]], [21, [0, 0, 0, 0]], [22, [0, 0, 0, 0]], [23, [0, 0, 0, 0]], [24, [0, 0, 0, 0]], [25, [0, 0, 0, 0]], [26, [0, 0, 0, 0]], [27, (107, 90, 1, 2)], [28, (95, 93, 9, 5)], [29, (93, 88, 15, 11)], [30, (91, 87, 17, 13)], [31, (90, 85, 19, 16)], [32, (90, 84, 22, 16)], [33, (86, 71, 26, 29)], [34, (85, 70, 26, 31)], [35, (84, 69, 29, 32)], [36, (84, 69, 34, 32)], [37, (82, 67, 38, 35)], [38, (82, 66, 40, 37)], [39, (81, 66, 42, 37)], [40, (81, 63, 45, 41)], [41, (81, 61, 48, 43)], [42, (81, 61, 48, 44)], [43, (80, 61, 50, 44)], [44, (81, 60, 51, 46)], [45, (81, 61, 51, 46)], [46, (81, 60, 52, 56)], [47, (84, 60, 50, 56)], [48, (84, 59, 54, 56)], [49, (85, 59, 70, 57)], [50, (85, 59, 70, 56)], [51, (85, 58, 71, 56)], [52, (85, 58, 71, 56)], [53, (85, 58, 71, 56)], [54, (85, 58, 70, 56)], [55, (85, 58, 65, 56)], [56, (85, 59, 66, 54)], [57, (85, 58, 66, 55)], [58, (85, 58, 67, 53)], [59, (85, 59, 67, 52)], [60, (85, 60, 69, 51)], [61, (85, 62, 79, 48)], [62, (85, 62, 83, 47)], [63, (85, 61, 85, 48)], [64, (85, 59, 85, 49)], [65, (85, 58, 61, 48)], [66, (86, 57, 60, 44)], [67, (86, 56, 58, 45)], [68, (86, 56, 52, 44)], [69, (86, 56, 53, 43)], [70, (87, 57, 54, 39)], [71, (87, 57, 53, 38)], [72, (87, 57, 53, 37)], [73, (87, 58, 53, 33)], [74, (87, 57, 53, 34)], [75, (101, 57, 39, 27)], [76, (103, 59, 37, 24)], [77, (109, 60, 30, 23)], [78, (114, 61, 25, 21)], [79, (114, 62, 24, 19)], [80, (117, 65, 19, 15)], [81, (125, 70, 9, 9)], [82, [0, 0, 0, 0]], [83, [0, 0, 0, 0]], [84, [0, 0, 0, 0]], [85, [0, 0, 0, 0]], [86, [0, 0, 0, 0]], [87, [0, 0, 0, 0]], [88, [0, 0, 0, 0]], [89, [0, 0, 0, 0]], [90, [0, 0, 0, 0]], [91, [0, 0, 0, 0]], [92, [0, 0, 0, 0]], [93, [0, 0, 0, 0]], [94, [0, 0, 0, 0]], [95, [0, 0, 0, 0]], [96, [0, 0, 0, 0]], [97, [0, 0, 0, 0]], [98, [0, 0, 0, 0]], [99, [0, 0, 0, 0]], [100, [0, 0, 0, 0]], [101, [0, 0, 0, 0]], [102, [0, 0, 0, 0]], [103, [0, 0, 0, 0]], [104, [0, 0, 0, 0]], [105, [0, 0, 0, 0]], [106, [0, 0, 0, 0]], [107, [0, 0, 0, 0]], [108, [0, 0, 0, 0]], [109, [0, 0, 0, 0]], [110, [0, 0, 0, 0]], [111, [0, 0, 0, 0]], [112, [0, 0, 0, 0]], [113, [0, 0, 0, 0]], [114, [0, 0, 0, 0]], [115, [0, 0, 0, 0]], [116, [0, 0, 0, 0]], [117, [0, 0, 0, 0]], [118, [0, 0, 0, 0]], [119, [0, 0, 0, 0]], [120, [0, 0, 0, 0]], [121, [0, 0, 0, 0]], [122, [0, 0, 0, 0]], [123, [0, 0, 0, 0]], [124, [0, 0, 0, 0]], [125, [0, 0, 0, 0]], [126, [0, 0, 0, 0]], [127, [0, 0, 0, 0]], [128, [0, 0, 0, 0]], [129, [0, 0, 0, 0]], [130, [0, 0, 0, 0]], [131, [0, 0, 0, 0]], [132, [0, 0, 0, 0]], [133, [0, 0, 0, 0]], [134, [0, 0, 0, 0]], [135, [0, 0, 0, 0]], [136, [0, 0, 0, 0]], [137, [0, 0, 0, 0]], [138, [0, 0, 0, 0]], [139, [0, 0, 0, 0]], [140, [0, 0, 0, 0]], [141, [0, 0, 0, 0]], [142, [0, 0, 0, 0]], [143, [0, 0, 0, 0]], [144, [0, 0, 0, 0]], [145, [0, 0, 0, 0]], [146, [0, 0, 0, 0]], [147, [0, 0, 0, 0]], [148, [0, 0, 0, 0]], [149, [0, 0, 0, 0]]], [[0, [0, 0, 0, 0]], [1, [0, 0, 0, 0]], [2, [0, 0, 0, 0]], [3, [0, 0, 0, 0]], [4, [0, 0, 0, 0]], [5, [0, 0, 0, 0]], [6, [0, 0, 0, 0]], [7, [0, 0, 0, 0]], [8, [0, 0, 0, 0]], [9, [0, 0, 0, 0]], [10, [0, 0, 0, 0]], [11, [0, 0, 0, 0]], [12, [0, 0, 0, 0]], [13, [0, 0, 0, 0]], [14, [0, 0, 0, 0]], [15, [0, 0, 0, 0]], [16, [0, 0, 0, 0]], [17, [0, 0, 0, 0]], [18, [0, 0, 0, 0]], [19, [0, 0, 0, 0]], [20, [0, 0, 0, 0]], [21, [0, 0, 0, 0]], [22, [0, 0, 0, 0]], [23, [0, 0, 0, 0]], [24, [0, 0, 0, 0]], [25, [0, 0, 0, 0]], [26, [0, 0, 0, 0]], [27, [0, 0, 0, 0]], [28, [0, 0, 0, 0]], [29, [0, 0, 0, 0]], [30, [0, 0, 0, 0]], [31, [0, 0, 0, 0]], [32, [0, 0, 0, 0]], [33, [0, 0, 0, 0]], [34, [0, 0, 0, 0]], [35, [0, 0, 0, 0]], [36, [0, 0, 0, 0]], [37, [0, 0, 0, 0]], [38, [0, 0, 0, 0]], [39, [0, 0, 0, 0]], [40, [0, 0, 0, 0]], [41, [0, 0, 0, 0]], [42, [0, 0, 0, 0]], [43, [0, 0, 0, 0]], [44, [0, 0, 0, 0]], [45, [0, 0, 0, 0]], [46, [0, 0, 0, 0]], [47, [0, 0, 0, 0]], [48, [0, 0, 0, 0]], [49, [0, 0, 0, 0]], [50, [0, 0, 0, 0]], [51, [0, 0, 0, 0]], [52, [0, 0, 0, 0]], [53, [0, 0, 0, 0]], [54, [0, 0, 0, 0]], [55, [0, 0, 0, 0]], [56, [0, 0, 0, 0]], [57, [0, 0, 0, 0]], [58, (154, 175, 1, 1)], [59, (154, 176, 1, 1)], [60, (154, 174, 2, 3)], [61, (154, 166, 10, 11)], [62, (153, 164, 17, 13)], [63, (152, 162, 21, 18)], [64, (152, 161, 22, 19)], [65, (146, 161, 29, 19)], [66, (146, 160, 29, 21)], [67, (146, 159, 30, 21)], [68, (146, 159, 30, 21)], [69, (145, 158, 32, 23)], [70, (146, 158, 32, 22)], [71, (145, 157, 34, 22)], [72, (146, 157, 33, 22)], [73, (146, 157, 34, 22)], [74, (132, 141, 41, 17)], [75, (148, 157, 33, 23)], [76, (133, 140, 40, 18)], [77, (133, 139, 40, 19)], [78, (133, 138, 40, 19)], [79, (134, 137, 38, 20)], [80, (134, 137, 41, 20)], [81, (134, 137, 41, 20)], [82, (133, 137, 43, 20)], [83, (133, 136, 43, 23)], [84, (133, 136, 43, 23)], [85, (133, 135, 43, 32)], [86, (133, 135, 43, 32)], [87, (133, 135, 43, 32)], [88, (133, 127, 43, 40)], [89, (133, 129, 43, 38)], [90, (133, 128, 42, 39)], [91, (132, 126, 43, 42)], [92, (131, 125, 43, 43)], [93, (129, 125, 44, 43)], [94, (126, 126, 47, 42)], [95, (125, 126, 48, 42)], [96, (124, 127, 50, 41)], [97, (121, 127, 52, 41)], [98, (120, 129, 52, 39)], [99, (120, 131, 52, 37)], [100, (120, 131, 49, 37)], [101, (129, 132, 39, 20)], [102, (130, 132, 40, 20)], [103, (130, 132, 39, 20)], [104, (135, 133, 34, 21)], [105, (136, 133, 33, 22)], [106, (137, 133, 33, 19)], [107, (138, 133, 33, 18)], [108, (139, 134, 15, 15)], [109, (140, 137, 12, 10)], [110, [0, 0, 0, 0]], [111, [0, 0, 0, 0]], [112, [0, 0, 0, 0]], [113, [0, 0, 0, 0]], [114, [0, 0, 0, 0]], [115, [0, 0, 0, 0]], [116, [0, 0, 0, 0]], [117, [0, 0, 0, 0]], [118, [0, 0, 0, 0]], [119, [0, 0, 0, 0]], [120, [0, 0, 0, 0]], [121, [0, 0, 0, 0]], [122, [0, 0, 0, 0]], [123, [0, 0, 0, 0]], [124, [0, 0, 0, 0]], [125, [0, 0, 0, 0]], [126, [0, 0, 0, 0]], [127, [0, 0, 0, 0]], [128, [0, 0, 0, 0]], [129, [0, 0, 0, 0]], [130, [0, 0, 0, 0]], [131, [0, 0, 0, 0]], [132, [0, 0, 0, 0]], [133, [0, 0, 0, 0]], [134, [0, 0, 0, 0]], [135, [0, 0, 0, 0]], [136, [0, 0, 0, 0]], [137, [0, 0, 0, 0]], [138, [0, 0, 0, 0]], [139, [0, 0, 0, 0]], [140, [0, 0, 0, 0]], [141, [0, 0, 0, 0]], [142, [0, 0, 0, 0]], [143, [0, 0, 0, 0]], [144, [0, 0, 0, 0]], [145, [0, 0, 0, 0]], [146, [0, 0, 0, 0]], [147, [0, 0, 0, 0]], [148, [0, 0, 0, 0]], [149, [0, 0, 0, 0]]], [[0, [0, 0, 0, 0]], [1, [0, 0, 0, 0]], [2, [0, 0, 0, 0]], [3, [0, 0, 0, 0]], [4, [0, 0, 0, 0]], [5, [0, 0, 0, 0]], [6, [0, 0, 0, 0]], [7, [0, 0, 0, 0]], [8, [0, 0, 0, 0]], [9, [0, 0, 0, 0]], [10, [0, 0, 0, 0]], [11, [0, 0, 0, 0]], [12, [0, 0, 0, 0]], [13, [0, 0, 0, 0]], [14, [0, 0, 0, 0]], [15, [0, 0, 0, 0]], [16, [0, 0, 0, 0]], [17, [0, 0, 0, 0]], [18, [0, 0, 0, 0]], [19, [0, 0, 0, 0]], [20, [0, 0, 0, 0]], [21, [0, 0, 0, 0]], [22, [0, 0, 0, 0]], [23, [0, 0, 0, 0]], [24, [0, 0, 0, 0]], [25, [0, 0, 0, 0]], [26, [0, 0, 0, 0]], [27, [0, 0, 0, 0]], [28, [0, 0, 0, 0]], [29, [0, 0, 0, 0]], [30, [0, 0, 0, 0]], [31, [0, 0, 0, 0]], [32, [0, 0, 0, 0]], [33, [0, 0, 0, 0]], [34, [0, 0, 0, 0]], [35, [0, 0, 0, 0]], [36, [0, 0, 0, 0]], [37, [0, 0, 0, 0]], [38, [0, 0, 0, 0]], [39, [0, 0, 0, 0]], [40, [0, 0, 0, 0]], [41, [0, 0, 0, 0]], [42, [0, 0, 0, 0]], [43, [0, 0, 0, 0]], [44, [0, 0, 0, 0]], [45, [0, 0, 0, 0]], [46, [0, 0, 0, 0]], [47, [0, 0, 0, 0]], [48, [0, 0, 0, 0]], [49, [0, 0, 0, 0]], [50, [0, 0, 0, 0]], [51, [0, 0, 0, 0]], [52, [0, 0, 0, 0]], [53, [0, 0, 0, 0]], [54, (154, 157, 1, 1)], [55, (153, 154, 8, 9)], [56, (142, 154, 21, 10)], [57, (140, 152, 27, 13)], [58, (139, 144, 31, 22)], [59, (136, 144, 36, 23)], [60, (135, 143, 46, 25)], [61, (135, 143, 48, 27)], [62, (134, 139, 53, 38)], [63, (134, 138, 54, 40)], [64, (134, 138, 54, 41)], [65, (134, 139, 55, 41)], [66, (133, 138, 57, 42)], [67, (133, 137, 58, 43)], [68, (132, 136, 60, 44)], [69, (132, 135, 60, 45)], [70, (132, 134, 60, 47)], [71, (132, 134, 61, 47)], [72, (132, 133, 61, 48)], [73, (132, 133, 66, 47)], [74, (132, 131, 66, 49)], [75, (132, 129, 67, 50)], [76, (131, 129, 68, 50)], [77, (130, 125, 70, 55)], [78, (129, 126, 71, 54)], [79, (127, 126, 73, 54)], [80, (126, 126, 74, 54)], [81, (125, 127, 75, 53)], [82, (125, 127, 75, 53)], [83, (125, 128, 76, 52)], [84, (124, 128, 78, 52)], [85, (124, 128, 78, 52)], [86, (123, 129, 79, 52)], [87, (123, 129, 78, 52)], [88, (123, 129, 78, 52)], [89, (123, 129, 78, 51)], [90, (123, 129, 76, 51)], [91, (124, 129, 74, 51)], [92, (124, 129, 73, 51)], [93, (124, 129, 73, 51)], [94, (125, 129, 72, 51)], [95, (125, 129, 71, 51)], [96, (126, 129, 69, 51)], [97, (126, 129, 69, 50)], [98, (126, 129, 69, 50)], [99, (126, 129, 68, 50)], [100, (127, 129, 67, 49)], [101, (127, 129, 66, 49)], [102, (127, 129, 65, 48)], [103, (136, 130, 54, 40)], [104, (141, 130, 48, 42)], [105, (143, 130, 46, 40)], [106, (144, 130, 43, 39)], [107, (144, 130, 44, 32)], [108, (145, 131, 41, 34)], [109, (146, 131, 40, 33)], [110, (147, 132, 38, 27)], [111, (148, 132, 36, 27)], [112, (149, 133, 36, 26)], [113, (150, 133, 26, 27)], [114, (152, 133, 21, 24)], [115, (153, 136, 21, 20)], [116, (159, 136, 15, 20)], [117, (159, 137, 14, 17)], [118, (160, 142, 10, 11)], [119, (161, 143, 8, 9)], [120, (162, 144, 6, 7)], [121, (163, 148, 2, 2)], [122, [0, 0, 0, 0]], [123, [0, 0, 0, 0]], [124, [0, 0, 0, 0]], [125, [0, 0, 0, 0]], [126, [0, 0, 0, 0]], [127, [0, 0, 0, 0]], [128, [0, 0, 0, 0]], [129, [0, 0, 0, 0]], [130, [0, 0, 0, 0]], [131, [0, 0, 0, 0]], [132, [0, 0, 0, 0]], [133, [0, 0, 0, 0]], [134, [0, 0, 0, 0]], [135, [0, 0, 0, 0]], [136, [0, 0, 0, 0]], [137, [0, 0, 0, 0]], [138, [0, 0, 0, 0]], [139, [0, 0, 0, 0]], [140, [0, 0, 0, 0]], [141, [0, 0, 0, 0]], [142, [0, 0, 0, 0]], [143, [0, 0, 0, 0]], [144, [0, 0, 0, 0]], [145, [0, 0, 0, 0]], [146, [0, 0, 0, 0]], [147, [0, 0, 0, 0]], [148, [0, 0, 0, 0]], [149, [0, 0, 0, 0]]], [[0, [0, 0, 0, 0]], [1, [0, 0, 0, 0]], [2, [0, 0, 0, 0]], [3, [0, 0, 0, 0]], [4, [0, 0, 0, 0]], [5, [0, 0, 0, 0]], [6, [0, 0, 0, 0]], [7, [0, 0, 0, 0]], [8, [0, 0, 0, 0]], [9, [0, 0, 0, 0]], [10, [0, 0, 0, 0]], [11, [0, 0, 0, 0]], [12, [0, 0, 0, 0]], [13, [0, 0, 0, 0]], [14, [0, 0, 0, 0]], [15, [0, 0, 0, 0]], [16, [0, 0, 0, 0]], [17, [0, 0, 0, 0]], [18, [0, 0, 0, 0]], [19, [0, 0, 0, 0]], [20, [0, 0, 0, 0]], [21, [0, 0, 0, 0]], [22, [0, 0, 0, 0]], [23, [0, 0, 0, 0]], [24, [0, 0, 0, 0]], [25, [0, 0, 0, 0]], [26, [0, 0, 0, 0]], [27, [0, 0, 0, 0]], [28, [0, 0, 0, 0]], [29, [0, 0, 0, 0]], [30, [0, 0, 0, 0]], [31, [0, 0, 0, 0]], [32, [0, 0, 0, 0]], [33, [0, 0, 0, 0]], [34, [0, 0, 0, 0]], [35, [0, 0, 0, 0]], [36, [0, 0, 0, 0]], [37, [0, 0, 0, 0]], [38, [0, 0, 0, 0]], [39, [0, 0, 0, 0]], [40, [0, 0, 0, 0]], [41, [0, 0, 0, 0]], [42, [0, 0, 0, 0]], [43, [0, 0, 0, 0]], [44, [0, 0, 0, 0]], [45, [0, 0, 0, 0]], [46, [0, 0, 0, 0]], [47, [0, 0, 0, 0]], [48, [0, 0, 0, 0]], [49, [0, 0, 0, 0]], [50, [0, 0, 0, 0]], [51, [0, 0, 0, 0]], [52, [0, 0, 0, 0]], [53, [0, 0, 0, 0]], [54, [0, 0, 0, 0]], [55, [0, 0, 0, 0]], [56, [0, 0, 0, 0]], [57, [0, 0, 0, 0]], [58, [0, 0, 0, 0]], [59, [0, 0, 0, 0]], [60, [0, 0, 0, 0]], [61, [0, 0, 0, 0]], [62, [0, 0, 0, 0]], [63, [0, 0, 0, 0]], [64, [0, 0, 0, 0]], [65, [0, 0, 0, 0]], [66, [0, 0, 0, 0]], [67, [0, 0, 0, 0]], [68, [0, 0, 0, 0]], [69, [0, 0, 0, 0]], [70, [0, 0, 0, 0]], [71, [0, 0, 0, 0]], [72, [0, 0, 0, 0]], [73, [0, 0, 0, 0]], [74, [0, 0, 0, 0]], [75, [0, 0, 0, 0]], [76, [0, 0, 0, 0]], [77, [0, 0, 0, 0]], [78, [0, 0, 0, 0]], [79, (160, 149, 3, 3)], [80, (158, 147, 6, 5)], [81, (157, 145, 10, 8)], [82, (156, 143, 12, 13)], [83, (155, 143, 14, 16)], [84, (154, 142, 17, 18)], [85, (153, 142, 29, 28)], [86, (153, 142, 30, 33)], [87, (151, 142, 33, 33)], [88, (148, 143, 36, 32)], [89, (147, 142, 37, 33)], [90, (146, 143, 38, 33)], [91, (146, 143, 39, 33)], [92, (146, 143, 40, 33)], [93, (146, 143, 40, 32)], [94, (146, 143, 41, 33)], [95, (145, 144, 42, 31)], [96, (156, 150, 32, 25)], [97, (156, 150, 31, 26)], [98, (155, 150, 31, 26)], [99, (156, 151, 31, 25)], [100, (156, 151, 33, 24)], [101, (156, 151, 32, 25)], [102, (157, 151, 31, 24)], [103, (157, 151, 29, 24)], [104, (158, 150, 28, 26)], [105, (159, 151, 25, 24)], [106, (159, 152, 23, 21)], [107, (159, 151, 22, 21)], [108, (174, 118, 18, 25)], [109, (173, 118, 20, 25)], [110, (173, 118, 20, 28)], [111, (173, 119, 20, 28)], [112, (172, 119, 19, 31)], [113, (173, 121, 19, 27)], [114, (173, 120, 18, 27)], [115, (172, 120, 20, 27)], [116, (173, 120, 18, 27)], [117, (173, 121, 17, 26)], [118, (172, 120, 17, 25)], [119, (173, 121, 15, 23)], [120, (173, 121, 15, 22)], [121, (172, 120, 15, 23)], [122, (172, 120, 15, 22)], [123, (173, 120, 12, 21)], [124, (172, 119, 12, 23)], [125, (173, 120, 10, 20)], [126, (173, 121, 10, 17)], [127, (174, 121, 7, 15)], [128, (174, 122, 6, 12)], [129, (172, 125, 7, 10)], [130, [0, 0, 0, 0]], [131, [0, 0, 0, 0]], [132, [0, 0, 0, 0]], [133, [0, 0, 0, 0]], [134, [0, 0, 0, 0]], [135, [0, 0, 0, 0]], [136, [0, 0, 0, 0]], [137, [0, 0, 0, 0]], [138, [0, 0, 0, 0]], [139, [0, 0, 0, 0]], [140, [0, 0, 0, 0]], [141, [0, 0, 0, 0]], [142, [0, 0, 0, 0]], [143, [0, 0, 0, 0]], [144, [0, 0, 0, 0]], [145, [0, 0, 0, 0]], [146, [0, 0, 0, 0]], [147, [0, 0, 0, 0]], [148, [0, 0, 0, 0]], [149, [0, 0, 0, 0]]], [[0, [0, 0, 0, 0]], [1, [0, 0, 0, 0]], [2, [0, 0, 0, 0]], [3, [0, 0, 0, 0]], [4, [0, 0, 0, 0]], [5, [0, 0, 0, 0]], [6, [0, 0, 0, 0]], [7, [0, 0, 0, 0]], [8, [0, 0, 0, 0]], [9, [0, 0, 0, 0]], [10, [0, 0, 0, 0]], [11, [0, 0, 0, 0]], [12, [0, 0, 0, 0]], [13, [0, 0, 0, 0]], [14, [0, 0, 0, 0]], [15, [0, 0, 0, 0]], [16, [0, 0, 0, 0]], [17, [0, 0, 0, 0]], [18, [0, 0, 0, 0]], [19, [0, 0, 0, 0]], [20, [0, 0, 0, 0]], [21, [0, 0, 0, 0]], [22, [0, 0, 0, 0]], [23, [0, 0, 0, 0]], [24, [0, 0, 0, 0]], [25, [0, 0, 0, 0]], [26, [0, 0, 0, 0]], [27, [0, 0, 0, 0]], [28, [0, 0, 0, 0]], [29, [0, 0, 0, 0]], [30, [0, 0, 0, 0]], [31, [0, 0, 0, 0]], [32, [0, 0, 0, 0]], [33, [0, 0, 0, 0]], [34, [0, 0, 0, 0]], [35, [0, 0, 0, 0]], [36, [0, 0, 0, 0]], [37, [0, 0, 0, 0]], [38, [0, 0, 0, 0]], [39, [0, 0, 0, 0]], [40, [0, 0, 0, 0]], [41, [0, 0, 0, 0]], [42, [0, 0, 0, 0]], [43, [0, 0, 0, 0]], [44, [0, 0, 0, 0]], [45, [0, 0, 0, 0]], [46, [0, 0, 0, 0]], [47, [0, 0, 0, 0]], [48, [0, 0, 0, 0]], [49, [0, 0, 0, 0]], [50, [0, 0, 0, 0]], [51, [0, 0, 0, 0]], [52, [0, 0, 0, 0]], [53, [0, 0, 0, 0]], [54, [0, 0, 0, 0]], [55, [0, 0, 0, 0]], [56, [0, 0, 0, 0]], [57, [0, 0, 0, 0]], [58, [0, 0, 0, 0]], [59, (94, 150, 3, 7)], [60, (92, 145, 6, 16)], [61, (92, 138, 14, 24)], [62, (70, 128, 41, 35)], [63, (68, 127, 44, 37)], [64, (67, 127, 50, 40)], [65, (66, 126, 52, 42)], [66, (64, 121, 56, 47)], [67, (63, 121, 58, 48)], [68, (61, 117, 61, 53)], [69, (60, 117, 62, 55)], [70, (59, 117, 65, 54)], [71, (58, 119, 69, 52)], [72, (58, 118, 70, 53)], [73, (58, 118, 70, 53)], [74, (57, 116, 72, 55)], [75, (54, 116, 76, 55)], [76, (54, 112, 77, 59)], [77, (54, 111, 79, 60)], [78, (53, 112, 81, 60)], [79, (53, 106, 81, 66)], [80, (53, 106, 81, 66)], [81, (54, 106, 81, 67)], [82, (54, 107, 81, 66)], [83, (55, 106, 81, 69)], [84, (55, 104, 82, 72)], [85, (55, 106, 82, 71)], [86, (56, 107, 85, 70)], [87, (59, 106, 90, 71)], [88, (59, 106, 94, 71)], [89, (55, 106, 96, 70)], [90, (54, 106, 97, 69)], [91, (54, 106, 95, 70)], [92, (54, 107, 93, 70)], [93, (53, 110, 94, 67)], [94, (53, 118, 93, 59)], [95, (73, 118, 72, 59)], [96, (53, 119, 90, 57)], [97, (73, 120, 70, 56)], [98, (53, 120, 90, 55)], [99, (54, 122, 89, 53)], [100, (54, 125, 89, 50)], [101, (55, 126, 89, 48)], [102, (55, 125, 89, 49)], [103, (56, 125, 89, 48)], [104, (69, 124, 76, 49)], [105, (57, 124, 90, 48)], [106, (58, 124, 89, 48)], [107, (64, 124, 84, 48)], [108, (75, 125, 72, 46)], [109, (81, 126, 66, 44)], [110, (61, 126, 87, 44)], [111, (61, 126, 87, 43)], [112, (62, 126, 85, 42)], [113, (72, 126, 75, 38)], [114, (74, 126, 73, 36)], [115, (82, 126, 65, 36)], [116, (85, 126, 61, 23)], [117, (69, 125, 77, 27)], [118, (70, 125, 76, 26)], [119, (89, 125, 56, 26)], [120, (89, 125, 56, 27)], [121, (89, 125, 56, 27)], [122, (75, 125, 69, 27)], [123, (88, 124, 56, 28)], [124, (88, 125, 56, 26)], [125, (89, 125, 55, 26)], [126, (91, 125, 53, 26)], [127, (92, 125, 51, 23)], [128, (111, 126, 31, 17)], [129, (111, 126, 30, 15)], [130, (111, 126, 30, 14)], [131, (111, 126, 29, 10)], [132, (111, 127, 28, 9)], [133, (117, 127, 20, 8)], [134, (126, 128, 11, 5)], [135, [0, 0, 0, 0]], [136, [0, 0, 0, 0]], [137, [0, 0, 0, 0]], [138, [0, 0, 0, 0]], [139, [0, 0, 0, 0]], [140, [0, 0, 0, 0]], [141, [0, 0, 0, 0]], [142, [0, 0, 0, 0]], [143, [0, 0, 0, 0]], [144, [0, 0, 0, 0]], [145, [0, 0, 0, 0]], [146, [0, 0, 0, 0]], [147, [0, 0, 0, 0]], [148, [0, 0, 0, 0]], [149, [0, 0, 0, 0]]], [[0, [0, 0, 0, 0]], [1, [0, 0, 0, 0]], [2, [0, 0, 0, 0]], [3, [0, 0, 0, 0]], [4, [0, 0, 0, 0]], [5, [0, 0, 0, 0]], [6, [0, 0, 0, 0]], [7, [0, 0, 0, 0]], [8, [0, 0, 0, 0]], [9, [0, 0, 0, 0]], [10, [0, 0, 0, 0]], [11, [0, 0, 0, 0]], [12, [0, 0, 0, 0]], [13, [0, 0, 0, 0]], [14, [0, 0, 0, 0]], [15, [0, 0, 0, 0]], [16, [0, 0, 0, 0]], [17, [0, 0, 0, 0]], [18, [0, 0, 0, 0]], [19, [0, 0, 0, 0]], [20, [0, 0, 0, 0]], [21, [0, 0, 0, 0]], [22, [0, 0, 0, 0]], [23, [0, 0, 0, 0]], [24, [0, 0, 0, 0]], [25, [0, 0, 0, 0]], [26, [0, 0, 0, 0]], [27, [0, 0, 0, 0]], [28, [0, 0, 0, 0]], [29, [0, 0, 0, 0]], [30, [0, 0, 0, 0]], [31, [0, 0, 0, 0]], [32, [0, 0, 0, 0]], [33, [0, 0, 0, 0]], [34, [0, 0, 0, 0]], [35, (155, 169, 1, 1)], [36, (153, 172, 6, 3)], [37, (151, 167, 13, 9)], [38, (151, 165, 15, 12)], [39, (150, 164, 16, 13)], [40, (148, 161, 16, 17)], [41, (143, 160, 23, 19)], [42, (132, 159, 35, 24)], [43, (123, 156, 43, 27)], [44, (124, 156, 42, 27)], [45, (123, 155, 46, 28)], [46, (120, 155, 48, 29)], [47, (118, 147, 52, 37)], [48, (118, 146, 53, 38)], [49, (115, 145, 56, 40)], [50, (114, 145, 57, 40)], [51, (113, 143, 58, 42)], [52, (114, 142, 58, 43)], [53, (113, 142, 60, 43)], [54, (113, 142, 61, 43)], [55, (113, 142, 61, 44)], [56, (113, 142, 61, 44)], [57, (113, 142, 60, 43)], [58, (113, 142, 60, 44)], [59, (114, 142, 59, 44)], [60, (114, 142, 59, 43)], [61, (114, 142, 60, 43)], [62, (114, 142, 60, 42)], [63, (114, 141, 60, 39)], [64, (114, 142, 60, 39)], [65, (107, 141, 68, 40)], [66, (117, 140, 58, 40)], [67, (120, 146, 56, 33)], [68, (110, 147, 66, 31)], [69, (112, 146, 64, 32)], [70, (125, 146, 51, 33)], [71, (126, 145, 51, 34)], [72, (128, 145, 48, 30)], [73, (129, 144, 47, 26)], [74, (132, 146, 43, 22)], [75, (135, 145, 41, 23)], [76, (136, 145, 40, 22)], [77, (137, 145, 39, 22)], [78, (141, 144, 35, 23)], [79, (148, 143, 28, 24)], [80, (149, 143, 26, 23)], [81, (151, 144, 24, 20)], [82, (150, 149, 24, 12)], [83, (151, 150, 22, 10)], [84, (150, 151, 19, 9)], [85, (151, 151, 11, 9)], [86, (152, 152, 9, 6)], [87, (151, 152, 6, 4)], [88, (153, 153, 1, 1)], [89, [0, 0, 0, 0]], [90, [0, 0, 0, 0]], [91, [0, 0, 0, 0]], [92, [0, 0, 0, 0]], [93, [0, 0, 0, 0]], [94, [0, 0, 0, 0]], [95, [0, 0, 0, 0]], [96, [0, 0, 0, 0]], [97, [0, 0, 0, 0]], [98, [0, 0, 0, 0]], [99, [0, 0, 0, 0]], [100, [0, 0, 0, 0]], [101, [0, 0, 0, 0]], [102, [0, 0, 0, 0]], [103, [0, 0, 0, 0]], [104, [0, 0, 0, 0]], [105, [0, 0, 0, 0]], [106, [0, 0, 0, 0]], [107, [0, 0, 0, 0]], [108, [0, 0, 0, 0]], [109, [0, 0, 0, 0]], [110, [0, 0, 0, 0]], [111, [0, 0, 0, 0]], [112, [0, 0, 0, 0]], [113, [0, 0, 0, 0]], [114, [0, 0, 0, 0]], [115, [0, 0, 0, 0]], [116, [0, 0, 0, 0]], [117, [0, 0, 0, 0]], [118, [0, 0, 0, 0]], [119, [0, 0, 0, 0]], [120, [0, 0, 0, 0]], [121, [0, 0, 0, 0]], [122, [0, 0, 0, 0]], [123, [0, 0, 0, 0]], [124, [0, 0, 0, 0]], [125, [0, 0, 0, 0]], [126, [0, 0, 0, 0]], [127, [0, 0, 0, 0]], [128, [0, 0, 0, 0]], [129, [0, 0, 0, 0]], [130, [0, 0, 0, 0]], [131, [0, 0, 0, 0]], [132, [0, 0, 0, 0]], [133, [0, 0, 0, 0]], [134, [0, 0, 0, 0]], [135, [0, 0, 0, 0]], [136, [0, 0, 0, 0]], [137, [0, 0, 0, 0]], [138, [0, 0, 0, 0]], [139, [0, 0, 0, 0]], [140, [0, 0, 0, 0]], [141, [0, 0, 0, 0]], [142, [0, 0, 0, 0]], [143, [0, 0, 0, 0]], [144, [0, 0, 0, 0]], [145, [0, 0, 0, 0]], [146, [0, 0, 0, 0]], [147, [0, 0, 0, 0]], [148, [0, 0, 0, 0]], [149, [0, 0, 0, 0]]], [[0, [0, 0, 0, 0]], [1, [0, 0, 0, 0]], [2, [0, 0, 0, 0]], [3, [0, 0, 0, 0]], [4, [0, 0, 0, 0]], [5, [0, 0, 0, 0]], [6, [0, 0, 0, 0]], [7, [0, 0, 0, 0]], [8, [0, 0, 0, 0]], [9, [0, 0, 0, 0]], [10, [0, 0, 0, 0]], [11, [0, 0, 0, 0]], [12, [0, 0, 0, 0]], [13, [0, 0, 0, 0]], [14, [0, 0, 0, 0]], [15, [0, 0, 0, 0]], [16, [0, 0, 0, 0]], [17, [0, 0, 0, 0]], [18, [0, 0, 0, 0]], [19, [0, 0, 0, 0]], [20, [0, 0, 0, 0]], [21, [0, 0, 0, 0]], [22, [0, 0, 0, 0]], [23, (108, 84, 4, 4)], [24, (107, 84, 5, 4)], [25, (105, 81, 8, 9)], [26, (98, 79, 19, 14)], [27, (97, 78, 24, 19)], [28, (97, 77, 25, 21)], [29, (94, 77, 28, 22)], [30, (92, 76, 29, 25)], [31, (92, 75, 29, 26)], [32, (93, 71, 29, 29)], [33, (93, 68, 33, 34)], [34, (90, 63, 39, 40)], [35, (83, 62, 47, 41)], [36, (80, 62, 50, 41)], [37, (80, 61, 51, 41)], [38, (82, 59, 51, 43)], [39, (82, 57, 52, 45)], [40, (82, 57, 53, 47)], [41, (83, 56, 59, 49)], [42, (81, 63, 61, 42)], [43, (92, 66, 49, 39)], [44, (82, 66, 61, 39)], [45, (82, 67, 61, 38)], [46, (82, 67, 59, 37)], [47, (82, 68, 60, 36)], [48, (82, 68, 61, 35)], [49, (82, 68, 61, 35)], [50, (82, 69, 62, 35)], [51, (83, 69, 62, 35)], [52, (84, 70, 61, 37)], [53, (85, 71, 61, 36)], [54, (93, 72, 55, 35)], [55, (94, 74, 55, 33)], [56, (95, 74, 55, 29)], [57, (96, 76, 53, 27)], [58, (96, 77, 54, 24)], [59, (96, 77, 54, 25)], [60, (96, 78, 54, 24)], [61, (99, 78, 41, 23)], [62, (100, 81, 33, 21)], [63, (100, 80, 37, 21)], [64, (100, 78, 36, 23)], [65, (99, 79, 36, 23)], [66, (100, 81, 34, 16)], [67, (101, 79, 30, 17)], [68, (100, 79, 17, 12)], [69, (103, 79, 14, 5)], [70, (105, 79, 14, 11)], [71, (112, 80, 1, 5)], [72, (112, 81, 1, 4)], [73, (112, 82, 1, 3)], [74, (112, 82, 1, 3)], [75, [0, 0, 0, 0]], [76, [0, 0, 0, 0]], [77, [0, 0, 0, 0]], [78, [0, 0, 0, 0]], [79, [0, 0, 0, 0]], [80, [0, 0, 0, 0]], [81, [0, 0, 0, 0]], [82, [0, 0, 0, 0]], [83, [0, 0, 0, 0]], [84, [0, 0, 0, 0]], [85, [0, 0, 0, 0]], [86, [0, 0, 0, 0]], [87, [0, 0, 0, 0]], [88, [0, 0, 0, 0]], [89, [0, 0, 0, 0]], [90, [0, 0, 0, 0]], [91, [0, 0, 0, 0]], [92, [0, 0, 0, 0]], [93, [0, 0, 0, 0]], [94, [0, 0, 0, 0]], [95, [0, 0, 0, 0]], [96, [0, 0, 0, 0]], [97, [0, 0, 0, 0]], [98, [0, 0, 0, 0]], [99, [0, 0, 0, 0]], [100, [0, 0, 0, 0]], [101, [0, 0, 0, 0]], [102, [0, 0, 0, 0]], [103, [0, 0, 0, 0]], [104, [0, 0, 0, 0]], [105, [0, 0, 0, 0]], [106, [0, 0, 0, 0]], [107, [0, 0, 0, 0]], [108, [0, 0, 0, 0]], [109, [0, 0, 0, 0]], [110, [0, 0, 0, 0]], [111, [0, 0, 0, 0]], [112, [0, 0, 0, 0]], [113, [0, 0, 0, 0]], [114, [0, 0, 0, 0]], [115, [0, 0, 0, 0]], [116, [0, 0, 0, 0]], [117, [0, 0, 0, 0]], [118, [0, 0, 0, 0]], [119, [0, 0, 0, 0]], [120, [0, 0, 0, 0]], [121, [0, 0, 0, 0]], [122, [0, 0, 0, 0]], [123, [0, 0, 0, 0]], [124, [0, 0, 0, 0]], [125, [0, 0, 0, 0]], [126, [0, 0, 0, 0]], [127, [0, 0, 0, 0]], [128, [0, 0, 0, 0]], [129, [0, 0, 0, 0]], [130, [0, 0, 0, 0]], [131, [0, 0, 0, 0]], [132, [0, 0, 0, 0]], [133, [0, 0, 0, 0]], [134, [0, 0, 0, 0]], [135, [0, 0, 0, 0]], [136, [0, 0, 0, 0]], [137, [0, 0, 0, 0]], [138, [0, 0, 0, 0]], [139, [0, 0, 0, 0]], [140, [0, 0, 0, 0]], [141, [0, 0, 0, 0]], [142, [0, 0, 0, 0]], [143, [0, 0, 0, 0]], [144, [0, 0, 0, 0]], [145, [0, 0, 0, 0]], [146, [0, 0, 0, 0]], [147, [0, 0, 0, 0]], [148, [0, 0, 0, 0]], [149, [0, 0, 0, 0]]], [[0, [0, 0, 0, 0]], [1, [0, 0, 0, 0]], [2, [0, 0, 0, 0]], [3, [0, 0, 0, 0]], [4, [0, 0, 0, 0]], [5, [0, 0, 0, 0]], [6, [0, 0, 0, 0]], [7, [0, 0, 0, 0]], [8, [0, 0, 0, 0]], [9, [0, 0, 0, 0]], [10, [0, 0, 0, 0]], [11, [0, 0, 0, 0]], [12, [0, 0, 0, 0]], [13, [0, 0, 0, 0]], [14, [0, 0, 0, 0]], [15, [0, 0, 0, 0]], [16, [0, 0, 0, 0]], [17, [0, 0, 0, 0]], [18, [0, 0, 0, 0]], [19, [0, 0, 0, 0]], [20, [0, 0, 0, 0]], [21, [0, 0, 0, 0]], [22, [0, 0, 0, 0]], [23, [0, 0, 0, 0]], [24, [0, 0, 0, 0]], [25, [0, 0, 0, 0]], [26, [0, 0, 0, 0]], [27, [0, 0, 0, 0]], [28, [0, 0, 0, 0]], [29, [0, 0, 0, 0]], [30, (116, 87, 3, 4)], [31, (114, 86, 9, 5)], [32, (112, 83, 12, 12)], [33, (109, 82, 18, 11)], [34, (104, 82, 24, 20)], [35, (103, 79, 27, 24)], [36, (100, 74, 30, 30)], [37, (100, 71, 32, 34)], [38, (95, 67, 40, 38)], [39, (93, 66, 44, 39)], [40, (92, 65, 46, 40)], [41, (92, 62, 47, 40)], [42, (91, 61, 50, 43)], [43, (91, 60, 67, 44)], [44, (91, 60, 74, 47)], [45, (91, 59, 74, 48)], [46, (90, 59, 76, 48)], [47, (90, 59, 76, 48)], [48, (89, 59, 77, 48)], [49, (89, 58, 79, 49)], [50, (90, 58, 81, 50)], [51, (93, 58, 79, 50)], [52, (94, 56, 75, 52)], [53, (95, 56, 99, 51)], [54, (96, 56, 99, 52)], [55, (95, 55, 100, 60)], [56, (95, 55, 110, 62)], [57, (95, 55, 110, 62)], [58, (91, 55, 114, 62)], [59, (91, 55, 115, 62)], [60, (91, 55, 116, 62)], [61, (91, 55, 116, 63)], [62, (89, 55, 119, 62)], [63, (88, 55, 120, 62)], [64, (88, 54, 120, 63)], [65, (88, 55, 120, 64)], [66, (88, 55, 119, 64)], [67, (88, 55, 118, 64)], [68, (89, 55, 116, 64)], [69, (89, 55, 116, 63)], [70, (89, 55, 116, 64)], [71, (88, 55, 117, 62)], [72, (89, 55, 115, 65)], [73, (85, 55, 119, 65)], [74, (90, 55, 114, 65)], [75, (91, 56, 112, 64)], [76, (92, 59, 111, 61)], [77, (92, 60, 111, 59)], [78, (93, 60, 110, 58)], [79, (93, 61, 109, 57)], [80, (94, 61, 108, 58)], [81, (94, 64, 106, 54)], [82, (95, 64, 104, 53)], [83, (97, 64, 101, 53)], [84, (97, 64, 101, 54)], [85, (97, 65, 100, 56)], [86, (97, 64, 100, 57)], [87, (97, 65, 99, 56)], [88, (98, 66, 98, 58)], [89, (98, 67, 99, 62)], [90, (99, 68, 97, 62)], [91, (100, 68, 96, 57)], [92, (101, 67, 96, 59)], [93, (104, 67, 92, 57)], [94, (108, 67, 80, 58)], [95, (109, 67, 77, 56)], [96, (110, 67, 76, 56)], [97, (111, 67, 75, 55)], [98, (112, 66, 73, 54)], [99, (109, 66, 75, 53)], [100, (107, 66, 77, 51)], [101, (108, 67, 70, 47)], [102, (108, 68, 69, 46)], [103, (132, 68, 45, 38)], [104, (134, 70, 38, 35)], [105, (135, 70, 27, 34)], [106, (136, 71, 17, 26)], [107, (142, 72, 10, 18)], [108, (142, 72, 9, 12)], [109, (145, 73, 5, 6)], [110, (147, 74, 3, 4)], [111, [0, 0, 0, 0]], [112, [0, 0, 0, 0]], [113, [0, 0, 0, 0]], [114, [0, 0, 0, 0]], [115, [0, 0, 0, 0]], [116, [0, 0, 0, 0]], [117, [0, 0, 0, 0]], [118, [0, 0, 0, 0]], [119, [0, 0, 0, 0]], [120, [0, 0, 0, 0]], [121, [0, 0, 0, 0]], [122, [0, 0, 0, 0]], [123, [0, 0, 0, 0]], [124, [0, 0, 0, 0]], [125, [0, 0, 0, 0]], [126, [0, 0, 0, 0]], [127, [0, 0, 0, 0]], [128, [0, 0, 0, 0]], [129, [0, 0, 0, 0]], [130, [0, 0, 0, 0]], [131, [0, 0, 0, 0]], [132, [0, 0, 0, 0]], [133, [0, 0, 0, 0]], [134, [0, 0, 0, 0]], [135, [0, 0, 0, 0]], [136, [0, 0, 0, 0]], [137, [0, 0, 0, 0]], [138, [0, 0, 0, 0]], [139, [0, 0, 0, 0]], [140, [0, 0, 0, 0]], [141, [0, 0, 0, 0]], [142, [0, 0, 0, 0]], [143, [0, 0, 0, 0]], [144, [0, 0, 0, 0]], [145, [0, 0, 0, 0]], [146, [0, 0, 0, 0]], [147, [0, 0, 0, 0]], [148, [0, 0, 0, 0]], [149, [0, 0, 0, 0]]], [[0, [0, 0, 0, 0]], [1, [0, 0, 0, 0]], [2, [0, 0, 0, 0]], [3, [0, 0, 0, 0]], [4, [0, 0, 0, 0]], [5, [0, 0, 0, 0]], [6, [0, 0, 0, 0]], [7, [0, 0, 0, 0]], [8, [0, 0, 0, 0]], [9, [0, 0, 0, 0]], [10, [0, 0, 0, 0]], [11, [0, 0, 0, 0]], [12, [0, 0, 0, 0]], [13, [0, 0, 0, 0]], [14, [0, 0, 0, 0]], [15, [0, 0, 0, 0]], [16, [0, 0, 0, 0]], [17, [0, 0, 0, 0]], [18, [0, 0, 0, 0]], [19, [0, 0, 0, 0]], [20, [0, 0, 0, 0]], [21, [0, 0, 0, 0]], [22, [0, 0, 0, 0]], [23, [0, 0, 0, 0]], [24, [0, 0, 0, 0]], [25, [0, 0, 0, 0]], [26, [0, 0, 0, 0]], [27, [0, 0, 0, 0]], [28, [0, 0, 0, 0]], [29, [0, 0, 0, 0]], [30, [0, 0, 0, 0]], [31, [0, 0, 0, 0]], [32, [0, 0, 0, 0]], [33, [0, 0, 0, 0]], [34, [0, 0, 0, 0]], [35, [0, 0, 0, 0]], [36, [0, 0, 0, 0]], [37, [0, 0, 0, 0]], [38, [0, 0, 0, 0]], [39, [0, 0, 0, 0]], [40, [0, 0, 0, 0]], [41, [0, 0, 0, 0]], [42, [0, 0, 0, 0]], [43, [0, 0, 0, 0]], [44, [0, 0, 0, 0]], [45, [0, 0, 0, 0]], [46, [0, 0, 0, 0]], [47, [0, 0, 0, 0]], [48, [0, 0, 0, 0]], [49, [0, 0, 0, 0]], [50, [0, 0, 0, 0]], [51, [0, 0, 0, 0]], [52, [0, 0, 0, 0]], [53, [0, 0, 0, 0]], [54, [0, 0, 0, 0]], [55, [0, 0, 0, 0]], [56, [0, 0, 0, 0]], [57, [0, 0, 0, 0]], [58, [0, 0, 0, 0]], [59, [0, 0, 0, 0]], [60, [0, 0, 0, 0]], [61, [0, 0, 0, 0]], [62, [0, 0, 0, 0]], [63, [0, 0, 0, 0]], [64, [0, 0, 0, 0]], [65, [0, 0, 0, 0]], [66, [0, 0, 0, 0]], [67, (163, 93, 2, 1)], [68, (122, 83, 8, 4)], [69, (121, 83, 11, 5)], [70, (120, 82, 13, 6)], [71, (118, 81, 15, 7)], [72, (147, 88, 25, 10)], [73, (146, 87, 25, 13)], [74, (146, 88, 26, 12)], [75, (110, 71, 24, 20)], [76, (107, 71, 27, 20)], [77, (107, 70, 27, 22)], [78, (106, 67, 47, 28)], [79, (106, 66, 48, 30)], [80, (106, 66, 67, 40)], [81, (106, 66, 63, 40)], [82, (106, 67, 63, 39)], [83, (106, 67, 62, 37)], [84, (107, 67, 61, 40)], [85, (117, 68, 51, 38)], [86, (111, 68, 42, 33)], [87, (112, 67, 57, 37)], [88, (112, 66, 57, 38)], [89, (111, 66, 58, 38)], [90, (112, 67, 57, 37)], [91, (112, 67, 57, 37)], [92, (113, 67, 44, 35)], [93, (113, 67, 44, 40)], [94, (125, 67, 33, 40)], [95, (125, 66, 30, 40)], [96, (153, 63, 37, 28)], [97, (152, 64, 38, 27)], [98, (126, 71, 29, 33)], [99, (127, 71, 27, 33)], [100, (130, 62, 24, 39)], [101, (130, 62, 24, 39)], [102, (131, 62, 25, 39)], [103, (128, 63, 28, 38)], [104, (130, 64, 26, 38)], [105, (129, 64, 27, 38)], [106, (129, 64, 27, 37)], [107, (129, 64, 56, 37)], [108, (130, 65, 53, 37)], [109, (129, 65, 52, 37)], [110, (129, 67, 51, 33)], [111, (131, 67, 49, 32)], [112, (131, 70, 47, 28)], [113, (131, 71, 46, 27)], [114, (131, 70, 46, 28)], [115, (131, 70, 43, 27)], [116, (132, 70, 39, 26)], [117, (132, 72, 38, 23)], [118, (133, 73, 20, 22)], [119, (134, 74, 19, 20)], [120, (136, 75, 17, 19)], [121, (136, 80, 13, 13)], [122, (139, 82, 9, 11)], [123, (144, 86, 4, 4)], [124, (145, 86, 2, 2)], [125, [0, 0, 0, 0]], [126, [0, 0, 0, 0]], [127, [0, 0, 0, 0]], [128, [0, 0, 0, 0]], [129, [0, 0, 0, 0]], [130, [0, 0, 0, 0]], [131, [0, 0, 0, 0]], [132, [0, 0, 0, 0]], [133, [0, 0, 0, 0]], [134, [0, 0, 0, 0]], [135, [0, 0, 0, 0]], [136, [0, 0, 0, 0]], [137, [0, 0, 0, 0]], [138, [0, 0, 0, 0]], [139, [0, 0, 0, 0]], [140, [0, 0, 0, 0]], [141, [0, 0, 0, 0]], [142, [0, 0, 0, 0]], [143, [0, 0, 0, 0]], [144, [0, 0, 0, 0]], [145, [0, 0, 0, 0]], [146, [0, 0, 0, 0]], [147, [0, 0, 0, 0]], [148, [0, 0, 0, 0]], [149, [0, 0, 0, 0]]]] - all_masks[:10]\n",
      "(10, 150, 2)  - np_all_masks.shape\n",
      "compute_brats_masks done.\n",
      "brats_markers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 9776.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[77, 51, 30, 108, 87, 82], [80, 56, 27, 85, 57, 54]]  - marks[:2]\n",
      "brats_markers done.\n",
      "load_brats_data...\n",
      "125 0 500  - len(files_path), len(mask_paths), len(unique_id)\n",
      "['../archive_BraTS2022/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/BraTS20_Validation_069/BraTS20_Validation_069_t1.nii', '../archive_BraTS2022/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData/BraTS20_Validation_056/BraTS20_Validation_056_t1.nii'] [] ['69', '69']  - files_path, mask_paths, unique_id\n",
      "load_brats_data done.\n",
      "compute_brats_masks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] - all_masks[:10]\n",
      "(0,)  - np_all_masks.shape\n",
      "compute_brats_masks done.\n",
      "brats_markers...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]  - marks[:2]\n",
      "brats_markers done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import fnmatch\n",
    "import os\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from medpy.io import load\n",
    "import cv2\n",
    "from collections import namedtuple, deque\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "\n",
    "f_train1 = \"path to Training samples\"\n",
    "f_ytrain1 = \"path to Training labels\"\n",
    "f_test1 = \"path to Test samples\"\n",
    "f_ytest1 = \"path to Test labels\"\n",
    "\n",
    "DATA_PATH = '../archive_BraTS2022'\n",
    "TRAIN_PATH = f'{DATA_PATH}/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n",
    "TEST_PATH = f'{DATA_PATH}/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n",
    "DATA_TYPES = ['flair', 't1', 't1ce', 't2', 'seg']\n",
    "N_FOLDS = 5\n",
    "\n",
    "class data_set(Dataset):\n",
    "  def __init__(self, path=TRAIN_PATH, transform = None):\n",
    "    ### Variable definition to be used in Data loader\n",
    "    self.max_z = 150 # max z value to be used in the data\n",
    "    self.path = path\n",
    "    self.transform_train = transform\n",
    "    \n",
    "    self.file_paths, self.mask_paths, self.unique_id = self._load_brats_data(path)\n",
    "    # TODO: 10개만 load하는 것은 Test를 위한 것이므로, 추후에는 전체 데이터를 load해야함.\n",
    "    self.file_paths, self.mask_paths, self.unique_id = self.file_paths[:10], self.mask_paths[:10], self.unique_id[:10]\n",
    "    self.all_masks = self._compute_brats_masks()\n",
    "    self.makers = np.array(self._brats_markers(self.all_masks))\n",
    "    \n",
    "    # TODO: 이 부분은 brats data를 위한 코드로 수정해야함.\n",
    "  def _load_brats_data(self, path):\n",
    "    print('load_brats_data...')\n",
    "    files_path = []\n",
    "    mask_paths = []\n",
    "    unique_id = []\n",
    "    for file_path in glob(f'{path}/*/*.nii'):\n",
    "        # t1 파일만 처리\n",
    "        if re.search(r\"_t1(?=\\.)\", file_path):\n",
    "            files_path.append(file_path)\n",
    "        # seg 파일만 처리\n",
    "        if \"seg\" in file_path:  # segmentation mask file\n",
    "            mask_paths.append(file_path)\n",
    "        unique_id.append(str(int(file_path.split('_')[-2])))\n",
    "    \n",
    "    print(len(files_path), len(mask_paths), len(unique_id), \" - len(files_path), len(mask_paths), len(unique_id)\")\n",
    "    print(files_path[:2], mask_paths[:2], unique_id[:2], \" - files_path, mask_paths, unique_id\")\n",
    "    print(\"load_brats_data done.\")\n",
    "    return sorted(files_path), sorted(mask_paths), sorted(list(set(unique_id)), key=lambda x: int(x))\n",
    "\n",
    "  def _compute_brats_masks(self):\n",
    "      print('compute_brats_masks...')\n",
    "      all_masks = []\n",
    "      for mask_path in tqdm(self.mask_paths):\n",
    "        mask = nib.load(mask_path).get_fdata()  # 마스크 데이터 로드\n",
    "        dummy_var = []\n",
    "        # visualization.ipynb를 참고\n",
    "        for j in range(self.max_z):\n",
    "          msk = mask[:, :, j] / mask.max() * 255  # 슬라이스 정규화 및 스케일링(0 ~ 1)\n",
    "          # msk = cv2.resize(msk, (256, 256))  # 이미지 크기 조정\n",
    "          _, bw_img = cv2.threshold(msk.astype(np.uint8), 10, 255, cv2.THRESH_OTSU)  # 이진화\n",
    "          # contours = [x_min, y_min, w, h]를 의미함.\n",
    "          contours, _ = cv2.findContours(bw_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)  # 컨투어 찾기\n",
    "          \n",
    "          # 가장 큰 컨투어 찾기\n",
    "          max_area = 0\n",
    "          max_rect = (0, 0, 0, 0)\n",
    "          for contour in contours:\n",
    "              rect = cv2.boundingRect(contour)\n",
    "              area = rect[2] * rect[3]  # rectangle의 넓이 (width * height)\n",
    "              if area > max_area:\n",
    "                  max_area = area\n",
    "                  max_rect = rect\n",
    "          \n",
    "          # 가장 큰 컨투어의 사각형 정보 저장\n",
    "          if max_area > 0:\n",
    "              dummy_var.append([j, max_rect])\n",
    "          else:\n",
    "              dummy_rect = [0, 0, 0, 0]  # 컨투어가 없을 경우\n",
    "              dummy_var.append([j, dummy_rect])\n",
    "        all_masks.append(dummy_var)\n",
    "      \n",
    "      print(all_masks[:10], \"- all_masks[:10]\")\n",
    "      np_all_masks = np.array(all_masks, dtype=object)\n",
    "      print(np_all_masks.shape, \" - np_all_masks.shape\")\n",
    "      print(\"compute_brats_masks done.\")  \n",
    "      return all_masks\n",
    "\n",
    "\n",
    "  def _brats_markers(self, slices_mask):\n",
    "      print('brats_markers...')\n",
    "      marks = []\n",
    "      for i in tqdm(range(len(slices_mask))):\n",
    "          x_min = []\n",
    "          y_min = []\n",
    "          w_max = []\n",
    "          h_max = []\n",
    "          indx_diff = []\n",
    "          for j in range(len(slices_mask[i])):\n",
    "              x_min.append(slices_mask[i][j][1][0])\n",
    "              y_min.append(slices_mask[i][j][1][1])\n",
    "              w_max.append(slices_mask[i][j][1][2])\n",
    "              h_max.append(slices_mask[i][j][1][3])\n",
    "\n",
    "              if slices_mask[i][j][1][0] != 0:\n",
    "                  indx_diff.append(slices_mask[i][j][0])\n",
    "          x_min = np.array(x_min)\n",
    "          y_min = np.array(y_min)\n",
    "          x_mn = np.min(x_min[np.nonzero(x_min)])\n",
    "          y_mn = np.min(y_min[np.nonzero(y_min)])\n",
    "          w_mx = np.array(w_max).max()\n",
    "          h_mx = np.array(h_max).max()\n",
    "          dim = [x_mn, y_mn, w_mx, h_mx]\n",
    "          d_mx = indx_diff[-1] - indx_diff[0]\n",
    "          z_mn = indx_diff[0]\n",
    "          marks.append([x_mn, y_mn, z_mn, w_mx, h_mx, d_mx])\n",
    "      print(marks[:2], \" - marks[:2]\")\n",
    "      print(\"brats_markers done.\")\n",
    "      return marks\n",
    "\n",
    "  def __len__(self):\n",
    "    ### size of file path\n",
    "    return len(self.file_paths)\n",
    "\n",
    "  def __getitem__(self, indx):\n",
    "    '''\n",
    "      Read the image given indx from len function\n",
    "    '''\n",
    "    # image_input = np.ones((145,256,256))\n",
    "    # image_input = np.ones(self.shape) # (240, 240, 155 - 5)\n",
    "    #for j in range(indx):\n",
    "    # 아래의 for loop는 145개의 slice를 읽어오는 코드임.\n",
    "    # 근데 이미 우리는 3D image가 있어서, medpy.io.load로 읽어오면 됨.\n",
    "    # cv2로 필요없음, 다른 부분의 code를 수정해서 (240, 240, 155)\n",
    "    # for i in range(image_input[-1]):\n",
    "    #     try:\n",
    "    #         img, _ = load(self.file_path[indx][i])\n",
    "    #         # img = cv2.resize(img.squeeze(), (256, 256))\n",
    "    #         \n",
    "    #         # img = self.transform_train(img.squeeze().astype('float'))\n",
    "    #         image_input[:, :, i] = img\n",
    "    #     except:\n",
    "    #         print(\"Check Index: \", indx)\n",
    "    \n",
    "    # box_gd = np.array([np.array(self.label)[indx][0], np.array(self.label)[indx][1], np.array(self.label)[indx][2],\n",
    "    #           np.array(self.label)[indx][3], np.array(self.label)[indx][4], np.array(self.label)[indx][5]])\n",
    "\n",
    "\n",
    "    # TODO : Transformation을 추가해야함.\n",
    "    img_input = load(self.file_paths[indx])\n",
    "    box_gd = self.makers[indx]\n",
    "\n",
    "    # 우리는 label이 필요없으므로 삭제.\n",
    "    # label_ = np.array(self.label)[indx][6]\n",
    "    return [img_input, box_gd]\n",
    "\n",
    "\n",
    "\n",
    "# train_data = data_set(file_path = f_train1, label = f_ytrain1, transform_train = transforms.Compose([\n",
    "#                                                                                    transforms.ToTensor(),\n",
    "#                                                                                 # TODO: t1 image에 Normalize하는게 맞는지 생각해야 함.\n",
    "#                                                                                 #    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "#                                                                                    ]))\n",
    "\n",
    "# unseen_data = data_set(file_path = f_test1, label = f_ytest1, transform_train = transforms.Compose([\n",
    "#                                                                                    transforms.ToTensor(),\n",
    "#                                                                                 #    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "#                                                                                    ]))\n",
    "\n",
    "train_data = data_set(path = TRAIN_PATH)\n",
    "unseen_data = data_set(path = TEST_PATH)\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(train_data, batch_size = 2,\n",
    "                        shuffle= True, num_workers= 2)\n",
    "dataloader_unseen = torch.utils.data.DataLoader(unseen_data, batch_size = 1,\n",
    "                        shuffle= True, num_workers= 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/ML/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/envs/ML/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'data_set' on <module '__main__' (built-in)>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/ML/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/opt/anaconda3/envs/ML/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "AttributeError: Can't get attribute 'data_set' on <module '__main__' (built-in)>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 78013) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1120\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1120\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/multiprocessing/connection.py:262\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/multiprocessing/connection.py:429\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 429\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/multiprocessing/connection.py:936\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 936\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 78013) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [17], line 108\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTraining Loss: \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTraining Accuracy: \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, train_loss, train_accuracy))\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m training_acc, training_loss\n\u001b[0;32m--> 108\u001b[0m t_phase1, l_phase1 \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_phase\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_dqn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [17], line 28\u001b[0m, in \u001b[0;36mtraining_phase\u001b[0;34m(dqn_model, dataloader)\u001b[0m\n\u001b[1;32m     26\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     27\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[1;32m     29\u001b[0m     images, box_gds, labels \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     30\u001b[0m     batches, depth, height, width \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1316\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1313\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1316\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1282\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1278\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1281\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1282\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1283\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1284\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1132\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1133\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(pids_str)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 78013) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d,MaxUnpool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from skimage import util\n",
    "from torchvision import transforms, models\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "def training_phase(dqn_model, dataloader):\n",
    "    training_acc = []\n",
    "    training_loss = []\n",
    "    for epoch in range(100):\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        total = 0.0\n",
    "        for data in dataloader:\n",
    "            images, box_gds, labels = data\n",
    "            batches, depth, height, width = images.shape\n",
    "            dqn_mask = []\n",
    "            loss_batch = torch.tensor(np.ones(batches))\n",
    "            reward_batch = torch.tensor(np.ones(batches))\n",
    "            dqn_mask = torch.tensor(np.ones((batches,1,50,height,width)))\n",
    "            for batch in range(batches):\n",
    "                # TODO: x, y, z가 80~120, 60~150, 50~95로 시작하는데, 이거는 따로 우리의 데이터에 맞게 수정해야함.\n",
    "                x_start = np.random.randint(80,120)\n",
    "                y_start = np.random.randint(60,200-50)\n",
    "                z_start = np.random.randint(50,145-50)\n",
    "                w, h, d = 50, 60, 50\n",
    "                start_state = [x_start, y_start, z_start, w, h, d]\n",
    "                game = \"continue\"\n",
    "                env = images[batch]\n",
    "                # 3D Labeling으로 x, y, z, w, h ,d가 필요함.\n",
    "                x_gd, y_gd, z_gd = box_gds[batch][0], box_gds[batch][1], box_gds[batch][2]\n",
    "                w_gd, h_gd, d_gd = box_gds[batch][3], box_gds[batch][4], box_gds[batch][5]\n",
    "                state_gd = [x_gd, y_gd, z_gd, w_gd, h_gd, d_gd]\n",
    "                start_eps = 1\n",
    "                end_eps = 0.004\n",
    "                start_step = 20\n",
    "                end_step = 5\n",
    "                prev_state = start_state.copy()\n",
    "                loss = 0\n",
    "                rewards = 0\n",
    "                for episodes in range(100):\n",
    "                    eps = max(0,(start_eps/int(1 + episodes)   - end_eps))\n",
    "                    step = max(end_step, start_step/int(1 + episodes) )\n",
    "\n",
    "                    # TODO: crop_reshape 함수가 하는 역할을 이해하고 우리의 데이터에 맞게 수정해야함.\n",
    "                    # crop_reshpe는 3D로 바꿔주는 함수, crop_reshape(env, x, y, z, w, h, d) -> env[x:x+w, y:y+h, z:z+d]\n",
    "                    # 즉, 원래 목적은 shape이 맞지 않은 3D image를 interpolation을 통해서 3D로 확장했음.\n",
    "                    # 우리의 데이터는 그럴 필요가 없기 때문에, 바로 넘겨줘도 될 듯 함.\n",
    "                    # 다만 prev_state가 정확히 어떤 의미인지 잘 모르겟음\n",
    "                    # prev_state : [x, y, z, w, h, d]\n",
    "                    prev_patch = crop_reshape(env, prev_state[0],prev_state[1],prev_state[2],prev_state[3],prev_state[4],prev_state[5])\n",
    "                    action = dqn_model.select_action(prev_patch, game, eps)\n",
    "                    if action != 6:\n",
    "                        nxt_state = dqn_model.next_state(prev_state, action, step)\n",
    "                        # print(nxt_state)\n",
    "                        nxt_patch = crop_reshape(env, nxt_state[0],nxt_state[1],nxt_state[2],nxt_state[3],nxt_state[4],nxt_state[5])\n",
    "                        game, reward = dqn_model.compute_reward(nxt_state, prev_state, state_gd, 10)\n",
    "                    else:\n",
    "                        game = \"END\"\n",
    "                        nxt_state = prev_state.copy()\n",
    "                        nxt_patch = crop_reshape(env, nxt_state[0],nxt_state[1],nxt_state[2],nxt_state[3],nxt_state[4],nxt_state[5])\n",
    "                        _, reward = dqn_model.compute_reward(nxt_state, prev_state, state_gd, 10)\n",
    "                    #print(np.asarray(action))\n",
    "                    dqn_model.store_transition(prev_patch, np.asarray(int(action)), reward, nxt_patch)\n",
    "\n",
    "                    if dqn_model.memory.memory_counter >= 1000:\n",
    "                        loss = dqn_model.optimize(1500)\n",
    "\n",
    "\n",
    "                    prev_state = nxt_state.copy()\n",
    "                    prev_patch = crop_reshape(env, nxt_state[0],nxt_state[1],nxt_state[2],nxt_state[3],nxt_state[4],nxt_state[5])\n",
    "                    rewards += reward\n",
    "                    #print(\"Episodes : \", episodes)\n",
    "                    if game == \"END\" or episodes == 2000:\n",
    "                        dqn_mask[batch] = nxt_patch.view(1, nxt_patch.shape[-3], nxt_patch.shape[-2],nxt_patch.shape[-1])\n",
    "                        loss_batch[batch] = (loss/int(1 + episodes))\n",
    "                        reward_batch[batch] = (rewards/int(1 + episodes))\n",
    "                        break\n",
    "                print(\"State Pred {:} , ground truth {:}, episodes {:}, batch {:}\".format(nxt_state , np.array(state_gd), episodes, batch))\n",
    "            try:\n",
    "                loss_per_batch = loss_batch.numpy().detach()\n",
    "            except:\n",
    "                loss_per_batch = loss_batch\n",
    "\n",
    "            # print(loss_per_batch.shape)\n",
    "            print(\"Loss_Rl {:.4f} \\tReward_RL {:.4f}\".format (loss_per_batch.mean(), reward_batch.mean()))\n",
    "        train_loss = train_loss/len(dataloader)\n",
    "        training_loss.append(train_loss)\n",
    "        train_accuracy = train_acc/total #100 *\n",
    "        training_acc.append(train_accuracy)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Accuracy: {:.6f}'.format(epoch, train_loss, train_accuracy))\n",
    "    return training_acc, training_loss\n",
    "\n",
    "t_phase1, l_phase1 = training_phase(my_dqn,  dataloader_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d,MaxUnpool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from skimage import util\n",
    "from torchvision import transforms, models\n",
    "from torch import optim\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "import torchvision\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "def testing_phase(dqn_model,classifier_model, dataloader, criterion):\n",
    "    testing_acc = []\n",
    "    testing_loss = []\n",
    "    pred_test = []\n",
    "    pred_true = []\n",
    "    final_box = []\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    total = 0.0\n",
    "    for data in dataloader:\n",
    "        images, box_gds, labels = data\n",
    "        batches, depth, height, width = images.shape\n",
    "        loss_batch = torch.tensor(np.ones(batches))\n",
    "        reward_batch = torch.tensor(np.ones(batches))\n",
    "        dqn_mask = torch.tensor(np.ones((batches,1,50,height,width)))\n",
    "        for batch in range(batches):\n",
    "            x_start = np.random.randint(80,120)\n",
    "            y_start = np.random.randint(60,200-50)\n",
    "            z_start = np.random.randint(50,145-50)\n",
    "            w, h, d = 50, 60, 50\n",
    "            start_state = [x_start, y_start, z_start, w, h, d]\n",
    "            game = \"continue\"\n",
    "            env = images[batch]\n",
    "            x_gd, y_gd, z_gd = box_gds[batch][0], box_gds[batch][1], box_gds[batch][2]\n",
    "            w_gd, h_gd, d_gd = box_gds[batch][3], box_gds[batch][4], box_gds[batch][5]\n",
    "            state_gd = [x_gd, y_gd, z_gd, w_gd, h_gd, d_gd]\n",
    "            start_eps = 1\n",
    "            end_eps = 0.004\n",
    "            start_step = 20\n",
    "            end_step = 5\n",
    "            prev_state = start_state.copy()\n",
    "            loss = 0\n",
    "            rewards = 0\n",
    "            for episodes in range(500):\n",
    "                eps = max(0,(start_eps/int(1 + episodes)   - end_eps))\n",
    "                step = max(end_step, start_step/int(1 + episodes) )\n",
    "\n",
    "                prev_patch = crop_reshape(env, prev_state[0],prev_state[1],prev_state[2],prev_state[3],prev_state[4],prev_state[5])\n",
    "                action = dqn_model.select_action_test(prev_patch)\n",
    "                if action != 6:\n",
    "                    nxt_state = dqn_model.next_state(prev_state, action, step)\n",
    "                    # print(nxt_state)\n",
    "                    nxt_patch = crop_reshape(env, nxt_state[0],nxt_state[1],nxt_state[2],nxt_state[3],nxt_state[4],nxt_state[5])\n",
    "                    game, reward = dqn_model.compute_reward(nxt_state, prev_state, state_gd, 10)\n",
    "                else:\n",
    "                    game = \"END\"\n",
    "                    nxt_state = prev_state.copy()\n",
    "                    nxt_patch = crop_reshape(env, nxt_state[0],nxt_state[1],nxt_state[2],nxt_state[3],nxt_state[4],nxt_state[5])\n",
    "                    _, reward = dqn_model.compute_reward(nxt_state,prev_state, state_gd, 10)\n",
    "                    #print(np.asarray(action))\n",
    "                prev_state = nxt_state.copy()\n",
    "                prev_patch = crop_reshape(env, nxt_state[0],nxt_state[1],nxt_state[2],nxt_state[3],nxt_state[4],nxt_state[5])\n",
    "                rewards += reward\n",
    "                #print(\"Episodes : \", episodes)\n",
    "                if game == \"END\" or episodes == 500:\n",
    "                    dqn_mask[batch] = nxt_patch.view(1, nxt_patch.shape[-3], nxt_patch.shape[-2],nxt_patch.shape[-1])\n",
    "                    loss_batch[batch] = (loss/int(1 + episodes))\n",
    "                    reward_batch[batch] = (rewards/int(1 + episodes))\n",
    "                    break\n",
    "            print(\"State Pred {:} , ground truth {:}, episodes {:}, batch {:}\".format(nxt_state , np.array(state_gd), episodes, batch))\n",
    "        try:\n",
    "            loss_per_batch = loss_batch.numpy().detach()\n",
    "        except:\n",
    "            loss_per_batch = loss_batch\n",
    "\n",
    "        # print(loss_per_batch.shape)\n",
    "        print(\"Loss_Rl {:.4f} \\tReward_RL {:.4f}\".format (loss_per_batch.mean(), reward_batch.mean()))\n",
    "        out_pred = classifier_model(dqn_mask.float(), images.view(batches, 1, depth, height, width).float())\n",
    "        loss = criterion(out_pred, labels.type(torch.LongTensor))#.view(-1,1) float()\n",
    "        test_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "        test_acc +=  binary_acc(out_pred, labels)\n",
    "        pred_test.append(int(out_pred.detach()))\n",
    "        pred_true.append(int(labels))\n",
    "        final_box.append([nxt_state, np.array(state_gd)])\n",
    "    test_loss = test_loss/len(dataloader)\n",
    "    testing_loss.append(test_loss)\n",
    "    test_acc = test_acc/total #100 *\n",
    "    testing_acc.append(test_acc)\n",
    "    print('Test Loss: {:.6f} \\tTest Accuracy: {:.6f}'.format( test_loss, test_acc))\n",
    "    return pred_test, final_box, test_loss, test_acc, pred_true\n",
    "\n",
    "\n",
    "a,b,c,d,e = testing_phase(my_dqn, class_model,  dataloader_unseen, criterion )\n",
    "\n",
    "\n",
    "def bar_plot(output_pred, output_true, unseen_loss, unseen_acc):\n",
    "  plt.figure(2)\n",
    "  cm = confusion_matrix(np.array(output_pred).squeeze(), np.array(output_true).squeeze())\n",
    "  recall = 100*cm[0,0]/(cm[0,0] + cm[1,0])\n",
    "  precision = 100*cm[0,0]/(cm[0,0] + cm[0,1])\n",
    "  params = ['Loss', 'Accuracy', 'TN', 'FP', 'FN', 'TP', 'Precision', 'Recall']\n",
    "  results = [unseen_loss, unseen_acc,cm[1,1],cm[0,1],cm[1,0],cm[0,0], precision, recall]\n",
    "  plt.bar(params, results)\n",
    "  for index,data in enumerate(results):\n",
    "    plt.text(x = index -0.2 , y = data  , s = f\"{int(data)}\" , fontdict=dict(fontsize=10))\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "bar_plot(a,e,c,100*d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
