{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "import math\n",
    "import torch\n",
    "\n",
    "''' Replay Buffer\n",
    "'''\n",
    "N_CHANNEL, N_HIGH, N_WEIGHT = 50, 256, 256\n",
    "# ReplayMemory의 역할은 state, action, reward, next_state를 저장하는 것\n",
    "# state, action, reward, next_state를 저장해서 학습할 때 사용함.\n",
    "class ReplayMemory():\n",
    "    def __init__(self, memory_size):\n",
    "        # self.memory의 역할은 state, action, reward, next_state를 저장하는 것\n",
    "        self.memory_counter = 0\n",
    "        self.memory_size = memory_size\n",
    "        self.state_memory = torch.FloatTensor(self.memory_size, 1, N_CHANNEL, N_HIGH, N_WEIGHT)\n",
    "        self.action_memory = torch.LongTensor(self.memory_size)\n",
    "        self.reward_memory = torch.FloatTensor(self.memory_size)\n",
    "        self.state__memory = torch.FloatTensor(self.memory_size, 1, N_CHANNEL, N_HIGH, N_WEIGHT)\n",
    "\n",
    "    def store(self, s, a, r, s_):\n",
    "        # 여기를 보면 index에 맞게 \"순서대로\" 저장하는 것을 볼 수 있음.\n",
    "        index = self.memory_counter % self.memory_size\n",
    "        self.state_memory[index] = s\n",
    "        self.action_memory[index] = torch.LongTensor([a.tolist()])\n",
    "        self.reward_memory[index] = torch.FloatTensor([r])\n",
    "        self.state__memory[index] = s_\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def sample(self, size):\n",
    "        sample_index = np.random.choice(self.memory_size, size)\n",
    "        state_sample = torch.FloatTensor(size,1,  N_CHANNEL, N_HIGH, N_WEIGHT)\n",
    "        action_sample = torch.LongTensor(size, 1)\n",
    "        reward_sample = torch.FloatTensor(size, 1)\n",
    "        state__sample = torch.FloatTensor(size, 1, N_CHANNEL, N_HIGH, N_WEIGHT)\n",
    "        for index in range(sample_index.size):\n",
    "            state_sample[index] = self.state_memory[sample_index[index]]\n",
    "            action_sample[index] = self.action_memory[sample_index[index]]\n",
    "            reward_sample[index] = self.reward_memory[sample_index[index]]\n",
    "            state__sample[index] = self.state__memory[sample_index[index]]\n",
    "        return state_sample, action_sample, reward_sample, state__sample\n",
    "\n",
    "\n",
    "''' Reshape state patches to full size input 50 x 256 x 256\n",
    "'''\n",
    "# crop_reshape 함수는 3D image를 (channel, 256, 256)으로 확장시키는 함수\n",
    "def crop_reshape(img, x,y,z,w,h,d):\n",
    "    img = np.array(img)\n",
    "    new_image = []\n",
    "    image_patch = img[z:z+d, x:x+h, y:y+w]\n",
    "    for i in range(image_patch.shape[0]):\n",
    "        new_image.append(cv2.resize(image_patch[i], (256,256)))\n",
    "    new_image = np.array(new_image)\n",
    "    return torch.tensor(new_image.reshape(1,1,new_image.shape[0], new_image.shape[1], new_image.shape[2])).float()\n",
    "\n",
    "'''Compute Accuracy for Training \n",
    "'''\n",
    "\n",
    "# binary_acc함수는 y_pred와 y_test를 받아서 정확도를 계산하는 함수\n",
    "def binary_acc(y_pred, y_test):\n",
    "    #y_pred[y_pred >= 0.5] = 1 \n",
    "    #y_pred[y_pred < 0.5] = 0\n",
    "    _, y_pred = y_pred.max(1)\n",
    "    correct_results_sum = (y_pred == y_test).sum().float()\n",
    "    acc = correct_results_sum#/y_test.shape[0]\n",
    "    acc = torch.round(acc)\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3Dmodels  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./src/DQN_based_Localization_figure.png\" alt=\"Description of the image\" width=\"600\" height=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d,MaxUnpool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from skimage import util\n",
    "from torchvision import transforms, models\n",
    "from torch import optim\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision\n",
    "from collections import namedtuple, deque\n",
    "import math\n",
    "\n",
    "# DQNSolver함수는 3D image를 받아서 7개의 action을 출력하는 DQN 모델을 생성하는 함수\n",
    "# DQN이란 Deep Q Network의 약자로 Q-learning을 딥러닝으로 구현한 것\n",
    "class DQNSolver(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Net with 3 conv3D layers and two linear layers\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DQNSolver, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(input_shape[0], 32, kernel_size=(5,5,5), stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((2, 2, 2)),\n",
    "            nn.Conv3d(32, 64, kernel_size=(5,5,5), stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((1, 2, 2)),\n",
    "            nn.Conv3d(64, 64, kernel_size=(3,3,3), stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((2, 2, 2)),\n",
    "        )\n",
    "        \n",
    "        # conv_out_size의 역할은 conv layer를 거치고 나온 output의 size를 계산하는 것\n",
    "        # _get_conv_out에 어떤 shape이 들어가냐면, \n",
    "        # DQNSolver의 예상 input_shape의 크기가 (1,50,256,256)라면, self.conv이후의 shape은  (64, 1, 7, 7)이므로\n",
    "        # conv_out_size는 64*1*7*7 = 3136이 됨.\n",
    "        # 이걸 self.fc layer를 이용해 7개로 줄여 action을 결정하게 됨.\n",
    "        # 여기서 7개의 액션은 각각의 방향으로 움직이는 것을 의미함.\n",
    "        # 0 - up, 1- down, 2 - right, 3- left, 4- top, 5 - bottom, 6 - terminate\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, n_actions)\n",
    "        )\n",
    "\n",
    "    \n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "        return self.fc(conv_out)\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Net with 3 conv3D layers and two linear layers\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape, num_features):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv3d(input_shape[0], 32, kernel_size=(5,5,5), stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((2, 2, 2)),\n",
    "            nn.Conv3d(32, 64, kernel_size=(5,5,5), stride=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((1, 2, 2)),\n",
    "            nn.Conv3d(64, 64, kernel_size=(3,3,3), stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.MaxPool3d((2, 2, 2)),\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(conv_out_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_features),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x).view(x.size()[0], -1)\n",
    "        return self.fc(conv_out)\n",
    "\n",
    "# concat_\n",
    "class concat_classifier(nn.Module):\n",
    "    def __init__(self, input_shape1,input_shape2, classes):\n",
    "        super(concat_classifier, self).__init__()\n",
    "\n",
    "        input_shape = input_shape1[1] + input_shape2[1]\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_shape, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, classes),\n",
    "            nn.Sigmoid()\n",
    "            )\n",
    "\n",
    "    def forward(self,x1, x2):\n",
    "        cat_out = torch.cat((x1,x2), dim = 1)\n",
    "        output = self.fc(cat_out)\n",
    "        return output\n",
    "\n",
    "\n",
    "class combine_model(nn.Module):\n",
    "    def __init__(self, model1, model2, model3):\n",
    "        super(combine_model, self).__init__()\n",
    "\n",
    "        self.model1 = model1\n",
    "        self.model2 = model2\n",
    "        self.model3 = model3\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        input1 = x1\n",
    "        input2 = x2\n",
    "\n",
    "        out1 = self.model1(input1)\n",
    "        out2 = self.model2(input2)\n",
    "        pred = self.model3(out1, out2)\n",
    "\n",
    "        return pred\n",
    "\n",
    "# 우리 데이터의 input shape이 어떻게 되는지 확인해야함\n",
    "policy_model = DQNSolver((1,50,256,256), 7)\n",
    "target_model = DQNSolver((1,50,256,256), 7)\n",
    "# hippocampus는 3D shape이 50, 256, 256인 이미지를 받아서 512개의 feature로 변환\n",
    "# hippocampus란 해마를 의미함.\n",
    "classifier_hippocampus = Classifier((1,50,256,256), 512)\n",
    "# global은 3D shape이 145, 256, 256인 이미지를 받아서 1024개의 feature로 변환\n",
    "# TODO: 둘 차이가 많이 나는데 이게 맞는건지 확인\n",
    "classifier_global = Classifier((1,145,256,256), 1024)\n",
    "final_model = concat_classifier((1,512), (1, 1024), 2)\n",
    "# final_model이 2개의 feature를 받아서 2개의 class로 분류하는 모델\n",
    "# 현재의 프로젝트 맥락에서 각각은 AD, CN을 의미함.\n",
    "# 여기서 AD는 Alzheimer's Disease, CN은 Control을 의미함.\n",
    "class_model = combine_model(classifier_hippocampus, classifier_global, final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d,MaxUnpool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from skimage import util\n",
    "from torchvision import transforms, models\n",
    "from torch import optim\n",
    "\n",
    "from medpy.io import load\n",
    "import cv2\n",
    "\n",
    "''' DQN Agent\n",
    "'''\n",
    "class DQNAgent(object):\n",
    "    def __init__(self, policy_model, target_model, replay_memory):\n",
    "            self.batch_size = 100\n",
    "            self.gamma = 0.99\n",
    "            self.eps = 1\n",
    "            self.target_update = 0\n",
    "            screen_height, screen_width, screen_depth = 256, 256, 145\n",
    "            self.n_actions = 7\n",
    "            self.policy_model = policy_model\n",
    "            self.target_model = target_model\n",
    "            self.target_model.eval()\n",
    "            self.optimizer = optim.Adam(self.policy_model.parameters(), lr = 0.00009)\n",
    "            self.loss_func = torch.nn.SmoothL1Loss()#nn.MSELoss()\n",
    "            self.memory = replay_memory\n",
    "\n",
    "    ''' Compute reward with L2 distance between centers of state and gd\n",
    "    '''\n",
    "    def compute_reward(self, actual_state, prev_state, ground_truth, threshold):\n",
    "            x,y,z,w,h,d = actual_state\n",
    "            x_p,y_p,z_p,w_p,h_p,d_p = prev_state\n",
    "            x_gd, y_gd, z_gd, w_gd, h_gd, d_gd = ground_truth\n",
    "\n",
    "            center = np.array([(x+w)/2,(y+h)/2, (z+d)/2])\n",
    "            center_gd = np.array([(x_gd + w_gd)/2,(y_gd + h_gd)/2, (z_gd + d_gd)/2])\n",
    "            center_p = np.array([(x_p + w_p)/2,(y_p + h_p )/2, (z_p + d_p)/2])\n",
    "            dist_l2 = np.linalg.norm(center - center_gd)\n",
    "            dist_l2_p = np.linalg.norm(center_p - center_gd)\n",
    "\n",
    "            if dist_l2 < threshold:\n",
    "                game = \"END\"\n",
    "                reward = 100\n",
    "                return game, reward\n",
    "            else:\n",
    "                game = \"continue\"\n",
    "                reward = min(1, -dist_l2) #dist_l2 - dist_l2_p #\n",
    "                return game, reward\n",
    "\n",
    "    ''' 0 - up, 1- down, 2 - right, 3- left, 4- top, 5 - bottom, 6 - terminate\n",
    "    '''\n",
    "    def next_state(self, prev_state, actn, step):\n",
    "            x,y,z,w,h,d = prev_state\n",
    "            # max_x:가 왜 255인지 모르겠음\n",
    "            max_x = 255\n",
    "            max_y = 255\n",
    "            max_z = 144\n",
    "            min_x = 0\n",
    "            min_y = 0\n",
    "            min_z = 0\n",
    "            \n",
    "            if actn == 0:\n",
    "                if x + w + step >= 255:\n",
    "                    x = 100\n",
    "                else:\n",
    "                    x = x + step\n",
    "            elif actn == 1:\n",
    "                if x - step <= 0:\n",
    "                    x = 100\n",
    "                else:\n",
    "                    x = x - step\n",
    "            elif actn == 2:\n",
    "                if y + h + step >= 255:\n",
    "                    y = 100\n",
    "                else:\n",
    "                    y = y + step\n",
    "            elif actn == 3:\n",
    "                if y - step <= 0:\n",
    "                    y = 100\n",
    "                else:\n",
    "                    y = y - step\n",
    "            elif actn == 4:\n",
    "                if z + d + step >= 144 :\n",
    "                    z = 50\n",
    "                else:\n",
    "                    z = z + step\n",
    "            elif actn == 5:\n",
    "                if z - step <= 0:\n",
    "                    z = 50\n",
    "                else:\n",
    "                    z = z - step\n",
    "\n",
    "            return [int(x),int(y),int(z),int(w),int(h),int(d)]\n",
    "\n",
    "    ''' Start with high eps then reduce eps, if game = END then action should be 6\n",
    "    '''\n",
    "    def select_action(self, state, game, eps ):\n",
    "            actn = 6\n",
    "            if game == \"continue\":\n",
    "                sample = random.random()\n",
    "                if sample < eps:\n",
    "                    actn = np.asarray(random.randrange(6))\n",
    "\n",
    "                else:\n",
    "                    out = self.policy_model(state)\n",
    "                    _, actn = torch.max(out.data, 1)\n",
    "\n",
    "                actn = np.array(actn)\n",
    "                return actn\n",
    "            else:\n",
    "                actn = np.array(actn)\n",
    "                return actn\n",
    "\n",
    "    def select_action_test(self, state):\n",
    "        out = self.target_model(state)\n",
    "        _, actn = torch.max(out.data,1)\n",
    "        return actn\n",
    "\n",
    "    def store_transition(self, s, a, r, s_):\n",
    "            self.memory.store(s, a, r, s_)\n",
    "\n",
    "    ''' Optimize model with replay memory\n",
    "    '''\n",
    "\n",
    "    def optimize(self, counter):\n",
    "\n",
    "            if self.target_update > counter:\n",
    "                self.target_model.load_state_dict(self.policy_model.state_dict())\n",
    "                self.target_update = 0\n",
    "                #print(\"Updating Target Net\")\n",
    "\n",
    "            self.target_update += 1\n",
    "\n",
    "\n",
    "            s_s, a_s, r_s, s__s = self.memory.sample(self.batch_size)\n",
    "\n",
    "            q_eval = self.policy_model(s_s).gather(1, a_s)\n",
    "            q_next = self.target_model(s__s).detach()\n",
    "            q_target = r_s + self.gamma * q_next.max(1)[0].view(self.batch_size, 1)\n",
    "            loss = self.loss_func(q_eval, q_target)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            return loss\n",
    "\n",
    "my_dqn = DQNAgent(policy_model, target_model, ReplayMemory(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data_Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/choihanjun/Library/Mobile Documents/com~apple~CloudDocs/Downloads/2024-1/[강화학습]/Project/RLovyou/training_practice.ipynb 셀 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/choihanjun/Library/Mobile%20Documents/com~apple~CloudDocs/Downloads/2024-1/%5B%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%5D/Project/RLovyou/training_practice.ipynb#X14sZmlsZQ%3D%3D?line=175'>176</a>\u001b[0m labels_ad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones((\u001b[39mlen\u001b[39m(sliced_markers_ad),\u001b[39m1\u001b[39m))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/choihanjun/Library/Mobile%20Documents/com~apple~CloudDocs/Downloads/2024-1/%5B%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%5D/Project/RLovyou/training_practice.ipynb#X14sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m labels_cn \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((\u001b[39mlen\u001b[39m(sliced_markers_cn),\u001b[39m1\u001b[39m))\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/choihanjun/Library/Mobile%20Documents/com~apple~CloudDocs/Downloads/2024-1/%5B%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%5D/Project/RLovyou/training_practice.ipynb#X14sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m label_cn \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mhstack([sliced_markers_cn, labels_cn])\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/choihanjun/Library/Mobile%20Documents/com~apple~CloudDocs/Downloads/2024-1/%5B%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%5D/Project/RLovyou/training_practice.ipynb#X14sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m label_ad \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhstack([sliced_markers_ad, labels_ad])\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/choihanjun/Library/Mobile%20Documents/com~apple~CloudDocs/Downloads/2024-1/%5B%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5%5D/Project/RLovyou/training_practice.ipynb#X14sZmlsZQ%3D%3D?line=182'>183</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mdata_cleaning_concat\u001b[39;00m():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ML/lib/python3.9/site-packages/numpy/core/shape_base.py:357\u001b[0m, in \u001b[0;36mhstack\u001b[0;34m(tup, dtype, casting)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39m# As a special case, dimension 0 of 1-dimensional arrays is \"horizontal\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mif\u001b[39;00m arrs \u001b[39mand\u001b[39;00m arrs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39;49mconcatenate(arrs, \u001b[39m0\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, casting\u001b[39m=\u001b[39;49mcasting)\n\u001b[1;32m    358\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39mreturn\u001b[39;00m _nx\u001b[39m.\u001b[39mconcatenate(arrs, \u001b[39m1\u001b[39m, dtype\u001b[39m=\u001b[39mdtype, casting\u001b[39m=\u001b[39mcasting)\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import fnmatch\n",
    "import os\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from medpy.io import load\n",
    "import cv2\n",
    "\n",
    "from collections import namedtuple, deque\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "''' Read files for AD and CN\n",
    "'''\n",
    "\n",
    "def mask_load(path):\n",
    "    files_id = []\n",
    "    mask = []\n",
    "    unique_id = []\n",
    "    for root, folder, file in os.walk(os.path.abspath(path)):\n",
    "        for masks in fnmatch.filter(file,\"*.nii\"):\n",
    "            y = os.path.join(root, masks).rsplit(\"\\\\\")[6]\n",
    "            uid = os.path.join(root, masks).rsplit(\"\\\\\")[8]\n",
    "            mask.append(os.path.join(root, masks))\n",
    "            files_id.append(y)\n",
    "            unique_id.append(uid)\n",
    "    return files_id, mask, unique_id\n",
    "\n",
    "path_ad = \"Path to AD\\\\ADNI\"\n",
    "all_files_ad_id, mask_ad, ad_unique_id = mask_load(path_ad)\n",
    "\n",
    "path_cn = \"Path to \\\\CN\\\\ADNI\"\n",
    "all_files_cn_id, mask_cn, cn_unique_id = mask_load(path_cn)\n",
    "\n",
    "\n",
    "#MP-RAGE_, SAG_MP-RAGE, MP-RAGE-, MPRAGE, MPRAGE_, MP-RAGE\n",
    "\n",
    "def data_load(path, file_id, unique_id):\n",
    "  file_path = []\n",
    "  f_path = []\n",
    "  for root, folder, file in os.walk(os.path.abspath(path)):\n",
    "    f_path = []\n",
    "    for filename in fnmatch.filter(file, \"*.dcm\" ):\n",
    "      id1 = os.path.join(root, filename).rsplit(\"\\\\\")[6]\n",
    "      if id1 in file_id:\n",
    "          id2 = os.path.join(root, filename).rsplit(\"\\\\\")[8]\n",
    "          if id2 in unique_id:\n",
    "              x = os.path.join(root, filename).rsplit(\"\\\\\")[7]\n",
    "              if (x == \"MP-RAGE_\" or x == \"SAG_MP-RAGE\" or x == \"MP-RAGE-\" or\n",
    "                   x == \"MPRAGE\" or x == \"MPRAGE_\" or x == \"MP-RAGE\") :\n",
    "                       f_path.append(os.path.join(root, filename))\n",
    "\n",
    "    if len(f_path) != 0:\n",
    "        file_path.append(f_path)\n",
    "  return file_path\n",
    "\n",
    "all_files_ad = data_load(path_ad, all_files_ad_id, ad_unique_id )\n",
    "\n",
    "def data_load_cn(path, file_id, unique_id):\n",
    "  file_path = []\n",
    "  f_path = []\n",
    "  for root, folder, file in os.walk(os.path.abspath(path)):\n",
    "    f_path = []\n",
    "    for filename in fnmatch.filter(file, \"*.dcm\" ):\n",
    "      id1 = os.path.join(root, filename).rsplit(\"\\\\\")[6]\n",
    "      if id1 in file_id:\n",
    "          id2 = os.path.join(root, filename).rsplit(\"\\\\\")[8]\n",
    "          if id2 in unique_id:\n",
    "              x = os.path.join(root, filename).rsplit(\"\\\\\")[7]\n",
    "              if ( x == \"MP-RAGE_\" or x == \"MP-RAGE-\" or x == \"MPRAGE\" or\n",
    "                   x == \"SAG_MP-RAGE_\" or x == \"MPRAGE_\" or x == \"MP_RAGE\" or\n",
    "                   x == \"MP-RAGE\" or x == \"MP-RAGE_\" or x == \"MP-RAGE__SERIES_2_\" or\n",
    "                   x == \"SAG_MP-RAGE\") :\n",
    "                       f_path.append(os.path.join(root, filename))\n",
    "\n",
    "    if len(f_path) != 0:\n",
    "        file_path.append(f_path)\n",
    "  return file_path\n",
    "\n",
    "all_files_cn = data_load_cn(path_cn, all_files_cn_id, cn_unique_id)\n",
    "\n",
    "''' Choose slices 25 - 125\n",
    "'''\n",
    "var1 = 15\n",
    "var2 = 159\n",
    "def slice_select(var1, var2, file_path):\n",
    "    new_filepath = []\n",
    "    for i in range(len(file_path)):\n",
    "        dummy_var = []\n",
    "        for j in range(len(file_path[i])):\n",
    "            if j>=var1 and j<= var2:\n",
    "                dummy_var.append(file_path[i][j])\n",
    "        new_filepath.append(dummy_var)\n",
    "    return new_filepath\n",
    "\n",
    "sliced_all_files_cn = slice_select(var1, var2, all_files_cn)\n",
    "sliced_all_files_ad = slice_select(var1, var2, all_files_ad)\n",
    "\n",
    "''' mask selection\n",
    "'''\n",
    "\n",
    "def compute_all_masks(var1, var2, file):\n",
    "    all_masks = []\n",
    "    for i in range(len(file)):\n",
    "        mask1,_ = load(file[i])\n",
    "        dummy_var = []\n",
    "        for j in range(mask1.shape[0]):\n",
    "            if j >= var1 and j <= var2:\n",
    "                msk = 255*mask1[j]/mask1[j].max()\n",
    "                msk = cv2.resize(msk, (256,256))\n",
    "                _, bw_img = cv2.threshold(msk.astype(np.uint8), 10, 255, cv2.THRESH_OTSU)\n",
    "                # _, bw_img = cv2.threshold(masks[indx_mx], 127, 255, cv2.THRESH_BINARY)\n",
    "                contours,_ = cv2.findContours(bw_img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "                if len(contours) != 0:\n",
    "                    rect =  cv2.boundingRect(contours[0])\n",
    "                    dummy_var.append([j, rect])\n",
    "                else:\n",
    "                    dummy_rect = [0,0,0,0]\n",
    "                    dummy_var.append([j, dummy_rect])\n",
    "\n",
    "        all_masks.append(dummy_var)\n",
    "    return all_masks\n",
    "\n",
    "\n",
    "sliced_masks_cn = compute_all_masks(var1, var2, mask_cn)\n",
    "sliced_masks_ad = compute_all_masks(var1, var2, mask_ad)\n",
    "\n",
    "''' Select mask dimension and markers for Hippocampus region\n",
    "'''\n",
    "def markers(slices_mask):\n",
    "    marks = []\n",
    "    for i in range(len(slices_mask)):\n",
    "        x_min = []\n",
    "        y_min = []\n",
    "        w_max = []\n",
    "        h_max = []\n",
    "        z_mn = 0\n",
    "        indx_diff = []\n",
    "        for j in range(len(slices_mask[i])):\n",
    "            x_min.append(slices_mask[i][j][1][0])\n",
    "            y_min.append(slices_mask[i][j][1][1])\n",
    "            w_max.append(slices_mask[i][j][1][2])\n",
    "            h_max.append(slices_mask[i][j][1][3])\n",
    "\n",
    "            if slices_mask[i][j][1][0] != 0:\n",
    "                indx_diff.append(slices_mask[i][j][0])\n",
    "        x_min = np.array(x_min)\n",
    "        y_min = np.array(y_min)\n",
    "        x_mn = np.min(x_min[np.nonzero(x_min)])\n",
    "        y_mn = np.min(y_min[np.nonzero(y_min)])\n",
    "        w_mx = np.array(w_max).max()\n",
    "        h_mx = np.array(h_max).max()\n",
    "        dim = [x_mn, y_mn, w_mx, h_mx]\n",
    "        # print(dim)\n",
    "        d_mx = indx_diff[-1] - indx_diff[0]\n",
    "        # print(diff)\n",
    "        z_mn = indx_diff[0]\n",
    "        marks.append([x_mn, y_mn, z_mn, w_mx, h_mx , d_mx])\n",
    "    return marks\n",
    "\n",
    "sliced_markers_cn = markers(sliced_masks_cn)\n",
    "sliced_markers_ad = markers(sliced_masks_ad)\n",
    "\n",
    "''' Concat labels 1 - AD,  0 -  CN\n",
    "'''\n",
    "labels_ad = np.ones((len(sliced_markers_ad),1))\n",
    "labels_cn = np.zeros((len(sliced_markers_cn),1))\n",
    "\n",
    "label_cn = np.hstack([sliced_markers_cn, labels_cn])\n",
    "label_ad = np.hstack([sliced_markers_ad, labels_ad])\n",
    "\n",
    "\n",
    "class data_cleaning_concat():\n",
    "    def __init__(self, data1, data2, label1, label2):\n",
    "        self.data1 = data1\n",
    "        self.data2 = data2\n",
    "        self.label1 = label1\n",
    "        self.label2 = label2\n",
    "\n",
    "    def _index_values(self, dataset):\n",
    "        index = []\n",
    "        for i in range(len(dataset)):\n",
    "            if len(dataset[i]) < 145:\n",
    "                index.append(i)\n",
    "        return index\n",
    "\n",
    "    def _pop_list(self, dataset, label, index):\n",
    "        for i in range(len(index)):\n",
    "            dataset.pop(index[i])\n",
    "            label.pop(index[i])\n",
    "        return dataset, label\n",
    "\n",
    "    def files_concat(self):\n",
    "        concat_data = []\n",
    "        concat_label = []\n",
    "\n",
    "        data1_ , label1_ = self._pop_list(self.data1, self.label1, self._index_values(self.data1))\n",
    "        data2_ , label2_ = self._pop_list(self.data2, self.label2, self._index_values(self.data2))\n",
    "\n",
    "        for i in range(len(data1_)):\n",
    "            concat_data.append(data1_[i])\n",
    "            concat_label.append(label1_[i])\n",
    "\n",
    "        for j in range(len(data2_)):\n",
    "            concat_data.append(data2_[j])\n",
    "            concat_label.append(label2_[j])\n",
    "\n",
    "        return shuffle(concat_data, concat_label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data_clean = data_cleaning_concat(sliced_all_files_ad, sliced_all_files_cn,\n",
    "                                                list(label_ad) , list(label_cn))\n",
    "total_data , total_label = data_clean.files_concat()\n",
    "\n",
    "def cross_valid_splits(data, label, fold):\n",
    "    fold_train = []\n",
    "    fold_test = []\n",
    "    fold_ytrain = []\n",
    "    fold_ytest = []\n",
    "\n",
    "    indxs1 = int(1*len(data)/5)\n",
    "    indxs2 = int(2*len(data)/5)\n",
    "    indxs3 = int(3*len(data)/5)\n",
    "    indxs4 = int(4*len(data)/5)\n",
    "    indxs5 = int(5*len(data)/5)\n",
    "\n",
    "    rn_trn = []\n",
    "    rn_tst = []\n",
    "    if fold == 1:\n",
    "        for i in range(0, indxs4):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "\n",
    "        for j in range(indxs4, indxs5):\n",
    "            fold_test.append(data[j])\n",
    "            fold_ytest.append(label[j])\n",
    "\n",
    "    elif fold == 2:\n",
    "        for i in range(0, indxs3):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "        for i in range(indxs4,indxs5):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "\n",
    "\n",
    "        for j in range(indxs3, indxs4):\n",
    "            fold_test.append(data[j])\n",
    "            fold_ytest.append(label[j])\n",
    "\n",
    "    elif fold == 3:\n",
    "        for i in range(0, indxs2):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "        for i in range(indxs3,indxs5):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "\n",
    "\n",
    "        for j in range(indxs2, indxs3):\n",
    "            fold_test.append(data[j])\n",
    "            fold_ytest.append(label[j])\n",
    "\n",
    "\n",
    "    elif fold == 4:\n",
    "        for i in range(0, indxs1):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "        for i in range(indxs2,indxs5):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "\n",
    "\n",
    "        for j in range(indxs1, indxs2):\n",
    "            fold_test.append(data[j])\n",
    "            fold_ytest.append(label[j])\n",
    "\n",
    "\n",
    "    elif fold == 5:\n",
    "        for i in range(indxs1, indxs5):\n",
    "            fold_train.append(data[i])\n",
    "            fold_ytrain.append(label[i])\n",
    "\n",
    "        for j in range(0, indxs1):\n",
    "            fold_test.append(data[j])\n",
    "            fold_ytest.append(label[j])\n",
    "\n",
    "\n",
    "    return fold_train, fold_test, np.array(fold_ytrain), np.array(fold_ytest)\n",
    "\n",
    "\n",
    "f_train1, f_test1, f_ytrain1, f_ytest1 = cross_valid_splits(total_data, total_label,1)\n",
    "\n",
    "f_train2, f_test2, f_ytrain2, f_ytest2 = cross_valid_splits(total_data, total_label,2)\n",
    "\n",
    "f_train3, f_test3, f_ytrain3, f_ytest3 = cross_valid_splits(total_data, total_label,3)\n",
    "\n",
    "f_train4, f_test4, f_ytrain4, f_ytest4 = cross_valid_splits(total_data, total_label,4)\n",
    "\n",
    "f_train5, f_test5, f_ytrain5, f_ytest5 = cross_valid_splits(total_data, total_label,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data_Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import random\n",
    "import fnmatch\n",
    "import os\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from medpy.io import load\n",
    "import cv2\n",
    "from collections import namedtuple, deque\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "\n",
    "f_train1 = \"path to Training samples\"\n",
    "f_ytrain1 = \"path to Training labels\"\n",
    "f_test1 = \"path to Test samples\"\n",
    "f_ytest1 = \"path to Test labels\"\n",
    "\n",
    "\n",
    "class data_set(Dataset):\n",
    "  def __init__(self, file_path, label, transform_train):\n",
    "    ### Variable definition to be used in Data loader\n",
    "    self.file_path = file_path\n",
    "    self.label = label\n",
    "    self.transform_train = transform_train\n",
    "\n",
    "  def __len__(self):\n",
    "    ### size of file path\n",
    "    return len(self.file_path)\n",
    "\n",
    "  def __getitem__(self, indx):\n",
    "    '''\n",
    "      Read the image given indx from len function\n",
    "    '''\n",
    "    image_input = np.ones((145,256,256))\n",
    "    #for j in range(indx):\n",
    "    for i in range(145):\n",
    "        try:\n",
    "            img, _ = load(self.file_path[indx][i])\n",
    "            img = cv2.resize(img.squeeze(), (256, 256))\n",
    "            img = self.transform_train(img.squeeze().astype('float'))\n",
    "            image_input[i,:,:] = img\n",
    "        except:\n",
    "            print(\"Check Index: \", indx)\n",
    "    box_gd = np.array([np.array(self.label)[indx][0], np.array(self.label)[indx][1], np.array(self.label)[indx][2],\n",
    "              np.array(self.label)[indx][3], np.array(self.label)[indx][4], np.array(self.label)[indx][5]])\n",
    "\n",
    "    label_ = np.array(self.label)[indx][6]\n",
    "    return [image_input, box_gd, label_]\n",
    "\n",
    "\n",
    "\n",
    "train_data = data_set(file_path = f_train1, label = f_ytrain1, transform_train = transforms.Compose([\n",
    "                                                                                   transforms.ToTensor(),\n",
    "                                                                                   transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                                                                   ]))\n",
    "\n",
    "unseen_data = data_set(file_path = f_test1, label = f_ytest1, transform_train = transforms.Compose([\n",
    "                                                                                   transforms.ToTensor(),\n",
    "                                                                                   transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "                                                                                   ]))\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(train_data, batch_size = 64,\n",
    "                        shuffle= True, num_workers= 0)\n",
    "dataloader_unseen = torch.utils.data.DataLoader(unseen_data, batch_size = 1,\n",
    "                        shuffle= True, num_workers= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d,MaxUnpool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from skimage import util\n",
    "from torchvision import transforms, models\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from utils import *\n",
    "\n",
    "def training_phase(dqn_model, classifier_model, dataloader, criterion, optimizer):\n",
    "    training_acc = []\n",
    "    training_loss = []\n",
    "    for epoch in range(100):\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        total = 0.0\n",
    "        for data in dataloader:\n",
    "            images, box_gds, labels = data\n",
    "            batches, depth, height, width = images.shape\n",
    "            dqn_mask = []\n",
    "            loss_batch = torch.tensor(np.ones(batches))\n",
    "            reward_batch = torch.tensor(np.ones(batches))\n",
    "            dqn_mask = torch.tensor(np.ones((batches,1,50,height,width)))\n",
    "            for batch in range(batches):\n",
    "                # TODO: x, y, z가 80~120, 60~150, 50~95로 시작하는데, 이거는 따로 우리의 데이터에 맞게 수정해야함.\n",
    "                x_start = np.random.randint(80,120)\n",
    "                y_start = np.random.randint(60,200-50)\n",
    "                z_start = np.random.randint(50,145-50)\n",
    "                w, h, d = 50, 60, 50\n",
    "                start_state = [x_start, y_start, z_start, w, h, d]\n",
    "                game = \"continue\"\n",
    "                env = images[batch]\n",
    "                # 3D Labeling으로 x, y, z, w, h ,d가 필요함.\n",
    "                x_gd, y_gd, z_gd = box_gds[batch][0], box_gds[batch][1], box_gds[batch][2]\n",
    "                w_gd, h_gd, d_gd = box_gds[batch][3], box_gds[batch][4], box_gds[batch][5]\n",
    "                state_gd = [x_gd, y_gd, z_gd, w_gd, h_gd, d_gd]\n",
    "                start_eps = 1\n",
    "                end_eps = 0.004\n",
    "                start_step = 20\n",
    "                end_step = 5\n",
    "                prev_state = start_state.copy()\n",
    "                loss = 0\n",
    "                rewards = 0\n",
    "                for episodes in range(100):\n",
    "                    eps = max(0,(start_eps/int(1 + episodes)   - end_eps))\n",
    "                    step = max(end_step, start_step/int(1 + episodes) )\n",
    "\n",
    "                    # TODO: crop_reshape 함수가 하는 역할을 이해하고 우리의 데이터에 맞게 수정해야함.\n",
    "                    # crop_reshpe는 3D로 바꿔주는 함수, crop_reshape(env, x, y, z, w, h, d) -> env[x:x+w, y:y+h, z:z+d]\n",
    "                    # 즉, 원래 목적은 shape이 맞지 않은 3D image를 interpolation을 통해서 3D로 확장했음.\n",
    "                    # 우리의 데이터는 그럴 필요가 없기 때문에, 바로 넘겨줘도 될 듯 함.\n",
    "                    # 다만 prev_state가 정확히 어떤 의미인지 잘 모르겟음\n",
    "                    # prev_state : [x, y, z, w, h, d]\n",
    "                    prev_patch = crop_reshape(env, prev_state[0],prev_state[1],prev_state[2],prev_state[3],prev_state[4],prev_state[5])\n",
    "                    action = dqn_model.select_action(prev_patch, game, eps)\n",
    "                    if action != 6:\n",
    "                        nxt_state = dqn_model.next_state(prev_state, action, step)\n",
    "                        # print(nxt_state)\n",
    "                        nxt_patch = crop_reshape(env, nxt_state[0],nxt_state[1],nxt_state[2],nxt_state[3],nxt_state[4],nxt_state[5])\n",
    "                        game, reward = dqn_model.compute_reward(nxt_state, prev_state, state_gd, 10)\n",
    "                    else:\n",
    "                        game = \"END\"\n",
    "                        nxt_state = prev_state.copy()\n",
    "                        nxt_patch = crop_reshape(env, nxt_state[0],nxt_state[1],nxt_state[2],nxt_state[3],nxt_state[4],nxt_state[5])\n",
    "                        _, reward = dqn_model.compute_reward(nxt_state, prev_state, state_gd, 10)\n",
    "                    #print(np.asarray(action))\n",
    "                    dqn_model.store_transition(prev_patch, np.asarray(int(action)), reward, nxt_patch)\n",
    "\n",
    "                    if dqn_model.memory.memory_counter >= 1000:\n",
    "                        loss = dqn_model.optimize(1500)\n",
    "\n",
    "\n",
    "                    prev_state = nxt_state.copy()\n",
    "                    prev_patch = crop_reshape(env, nxt_state[0],nxt_state[1],nxt_state[2],nxt_state[3],nxt_state[4],nxt_state[5])\n",
    "                    rewards += reward\n",
    "                    #print(\"Episodes : \", episodes)\n",
    "                    if game == \"END\" or episodes == 2000:\n",
    "                        dqn_mask[batch] = nxt_patch.view(1, nxt_patch.shape[-3], nxt_patch.shape[-2],nxt_patch.shape[-1])\n",
    "                        loss_batch[batch] = (loss/int(1 + episodes))\n",
    "                        reward_batch[batch] = (rewards/int(1 + episodes))\n",
    "                        break\n",
    "                print(\"State Pred {:} , ground truth {:}, episodes {:}, batch {:}\".format(nxt_state , np.array(state_gd), episodes, batch))\n",
    "            try:\n",
    "                loss_per_batch = loss_batch.numpy().detach()\n",
    "            except:\n",
    "                loss_per_batch = loss_batch\n",
    "\n",
    "            # print(loss_per_batch.shape)\n",
    "            print(\"Loss_Rl {:.4f} \\tReward_RL {:.4f}\".format (loss_per_batch.mean(), reward_batch.mean()))\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            # print(dqn_mask.shape)\n",
    "            out_pred = classifier_model(dqn_mask.float(), images.view(batches, 1, depth, height, width).float())\n",
    "            # print(out_pred)\n",
    "            # print(labels)\n",
    "            loss = criterion(out_pred, labels.type(torch.LongTensor))#.view(-1,1), .float()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            total += labels.size(0)\n",
    "            train_acc +=  binary_acc(out_pred, labels)\n",
    "            print(train_acc)\n",
    "            print(total)\n",
    "            # print(labels.size(0))\n",
    "        train_loss = train_loss/len(dataloader)\n",
    "        training_loss.append(train_loss)\n",
    "        train_accuracy = train_acc/total #100 *\n",
    "        training_acc.append(train_accuracy)\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tTraining Accuracy: {:.6f}'.format(epoch, train_loss, train_accuracy))\n",
    "    return training_acc, training_loss\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()#nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(class_model.parameters(), lr= 0.00009,  weight_decay=1e-5)\n",
    "t_phase1, l_phase1 = training_phase(my_dqn, class_model,  dataloader_train, criterion, optimizer )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d,MaxUnpool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from skimage import util\n",
    "from torchvision import transforms, models\n",
    "from torch import optim\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import cv2\n",
    "import torchvision\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "def testing_phase(dqn_model,classifier_model, dataloader, criterion):\n",
    "    testing_acc = []\n",
    "    testing_loss = []\n",
    "    pred_test = []\n",
    "    pred_true = []\n",
    "    final_box = []\n",
    "    test_loss = 0.0\n",
    "    test_acc = 0.0\n",
    "    total = 0.0\n",
    "    for data in dataloader:\n",
    "        images, box_gds, labels = data\n",
    "        batches, depth, height, width = images.shape\n",
    "        loss_batch = torch.tensor(np.ones(batches))\n",
    "        reward_batch = torch.tensor(np.ones(batches))\n",
    "        dqn_mask = torch.tensor(np.ones((batches,1,50,height,width)))\n",
    "        for batch in range(batches):\n",
    "            x_start = np.random.randint(80,120)\n",
    "            y_start = np.random.randint(60,200-50)\n",
    "            z_start = np.random.randint(50,145-50)\n",
    "            w, h, d = 50, 60, 50\n",
    "            start_state = [x_start, y_start, z_start, w, h, d]\n",
    "            game = \"continue\"\n",
    "            env = images[batch]\n",
    "            x_gd, y_gd, z_gd = box_gds[batch][0], box_gds[batch][1], box_gds[batch][2]\n",
    "            w_gd, h_gd, d_gd = box_gds[batch][3], box_gds[batch][4], box_gds[batch][5]\n",
    "            state_gd = [x_gd, y_gd, z_gd, w_gd, h_gd, d_gd]\n",
    "            start_eps = 1\n",
    "            end_eps = 0.004\n",
    "            start_step = 20\n",
    "            end_step = 5\n",
    "            prev_state = start_state.copy()\n",
    "            loss = 0\n",
    "            rewards = 0\n",
    "            for episodes in range(500):\n",
    "                eps = max(0,(start_eps/int(1 + episodes)   - end_eps))\n",
    "                step = max(end_step, start_step/int(1 + episodes) )\n",
    "\n",
    "                prev_patch = crop_reshape(env, prev_state[0],prev_state[1],prev_state[2],prev_state[3],prev_state[4],prev_state[5])\n",
    "                action = dqn_model.select_action_test(prev_patch)\n",
    "                if action != 6:\n",
    "                    nxt_state = dqn_model.next_state(prev_state, action, step)\n",
    "                    # print(nxt_state)\n",
    "                    nxt_patch = crop_reshape(env, nxt_state[0],nxt_state[1],nxt_state[2],nxt_state[3],nxt_state[4],nxt_state[5])\n",
    "                    game, reward = dqn_model.compute_reward(nxt_state, prev_state, state_gd, 10)\n",
    "                else:\n",
    "                    game = \"END\"\n",
    "                    nxt_state = prev_state.copy()\n",
    "                    nxt_patch = crop_reshape(env, nxt_state[0],nxt_state[1],nxt_state[2],nxt_state[3],nxt_state[4],nxt_state[5])\n",
    "                    _, reward = dqn_model.compute_reward(nxt_state,prev_state, state_gd, 10)\n",
    "                    #print(np.asarray(action))\n",
    "                prev_state = nxt_state.copy()\n",
    "                prev_patch = crop_reshape(env, nxt_state[0],nxt_state[1],nxt_state[2],nxt_state[3],nxt_state[4],nxt_state[5])\n",
    "                rewards += reward\n",
    "                #print(\"Episodes : \", episodes)\n",
    "                if game == \"END\" or episodes == 500:\n",
    "                    dqn_mask[batch] = nxt_patch.view(1, nxt_patch.shape[-3], nxt_patch.shape[-2],nxt_patch.shape[-1])\n",
    "                    loss_batch[batch] = (loss/int(1 + episodes))\n",
    "                    reward_batch[batch] = (rewards/int(1 + episodes))\n",
    "                    break\n",
    "            print(\"State Pred {:} , ground truth {:}, episodes {:}, batch {:}\".format(nxt_state , np.array(state_gd), episodes, batch))\n",
    "        try:\n",
    "            loss_per_batch = loss_batch.numpy().detach()\n",
    "        except:\n",
    "            loss_per_batch = loss_batch\n",
    "\n",
    "        # print(loss_per_batch.shape)\n",
    "        print(\"Loss_Rl {:.4f} \\tReward_RL {:.4f}\".format (loss_per_batch.mean(), reward_batch.mean()))\n",
    "        out_pred = classifier_model(dqn_mask.float(), images.view(batches, 1, depth, height, width).float())\n",
    "        loss = criterion(out_pred, labels.type(torch.LongTensor))#.view(-1,1) float()\n",
    "        test_loss += loss.item()\n",
    "        total += labels.size(0)\n",
    "        test_acc +=  binary_acc(out_pred, labels)\n",
    "        pred_test.append(int(out_pred.detach()))\n",
    "        pred_true.append(int(labels))\n",
    "        final_box.append([nxt_state, np.array(state_gd)])\n",
    "    test_loss = test_loss/len(dataloader)\n",
    "    testing_loss.append(test_loss)\n",
    "    test_acc = test_acc/total #100 *\n",
    "    testing_acc.append(test_acc)\n",
    "    print('Test Loss: {:.6f} \\tTest Accuracy: {:.6f}'.format( test_loss, test_acc))\n",
    "    return pred_test, final_box, test_loss, test_acc, pred_true\n",
    "\n",
    "\n",
    "a,b,c,d,e = testing_phase(my_dqn, class_model,  dataloader_unseen, criterion )\n",
    "\n",
    "\n",
    "def bar_plot(output_pred, output_true, unseen_loss, unseen_acc):\n",
    "  plt.figure(2)\n",
    "  cm = confusion_matrix(np.array(output_pred).squeeze(), np.array(output_true).squeeze())\n",
    "  recall = 100*cm[0,0]/(cm[0,0] + cm[1,0])\n",
    "  precision = 100*cm[0,0]/(cm[0,0] + cm[0,1])\n",
    "  params = ['Loss', 'Accuracy', 'TN', 'FP', 'FN', 'TP', 'Precision', 'Recall']\n",
    "  results = [unseen_loss, unseen_acc,cm[1,1],cm[0,1],cm[1,0],cm[0,0], precision, recall]\n",
    "  plt.bar(params, results)\n",
    "  for index,data in enumerate(results):\n",
    "    plt.text(x = index -0.2 , y = data  , s = f\"{int(data)}\" , fontdict=dict(fontsize=10))\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "\n",
    "bar_plot(a,e,c,100*d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
