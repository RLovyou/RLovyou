{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-05T23:59:57.437872Z","iopub.status.busy":"2023-05-05T23:59:57.437258Z","iopub.status.idle":"2023-05-05T23:59:58.023373Z","shell.execute_reply":"2023-05-05T23:59:58.021825Z","shell.execute_reply.started":"2023-05-05T23:59:57.437807Z"},"trusted":true},"outputs":[],"source":["import os\n","from glob import glob\n","\n","import nibabel as nib\n","import numpy as np\n","import pandas as pd\n","from scipy import ndimage"]},{"cell_type":"markdown","metadata":{},"source":["## Project Configuration"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T23:59:58.026871Z","iopub.status.busy":"2023-05-05T23:59:58.026442Z","iopub.status.idle":"2023-05-05T23:59:58.033349Z","shell.execute_reply":"2023-05-05T23:59:58.031755Z","shell.execute_reply.started":"2023-05-05T23:59:58.026832Z"},"trusted":true},"outputs":[],"source":["DATA_PATH = '../archive_BraTS2022'\n","TRAIN_PATH = f'{DATA_PATH}/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n","TEST_PATH = f'{DATA_PATH}/BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData'\n","DATA_TYPES = ['flair', 't1', 't1ce', 't2', 'seg']\n","N_FOLDS = 5"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-05-05T23:59:58.036033Z","iopub.status.busy":"2023-05-05T23:59:58.03541Z","iopub.status.idle":"2023-05-06T00:00:03.403092Z","shell.execute_reply":"2023-05-06T00:00:03.401399Z","shell.execute_reply.started":"2023-05-05T23:59:58.03598Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[TRAIN] Number of flair images: 369\n","[TRAIN] Number of t1 images: 369\n","[TRAIN] Number of t1ce images: 369\n","[TRAIN] Number of t2 images: 369\n","[TRAIN] Number of seg images: 369\n","\n","[TEST] Number of flair images: 125\n","[TEST] Number of t1 images: 125\n","[TEST] Number of t1ce images: 125\n","[TEST] Number of t2 images: 125\n","[TEST] Number of seg images: 0\n"]}],"source":["train_data_paths = {\n","    data_type: sorted(\n","        glob(f'{TRAIN_PATH}/**/*_{data_type}.nii')\n","    ) for data_type in DATA_TYPES\n","}\n","train_data_paths['seg'].append(f'{TRAIN_PATH}/BraTS20_Training_355/W39_1998.09.19_Seg.nii')\n","train_data_paths['seg'] = sorted(train_data_paths['seg'])\n","\n","for k, v in train_data_paths.items():\n","    print(f'[TRAIN] Number of {k} images: {len(v)}')\n","print()\n","test_data_paths = {\n","    data_type: sorted(\n","        glob(f'{TEST_PATH}/**/*_{data_type}.nii')\n","    ) for data_type in DATA_TYPES\n","}\n","\n","for k, v in test_data_paths.items():\n","    print(f'[TEST] Number of {k} images: {len(v)}')"]},{"cell_type":"markdown","metadata":{},"source":["## Loading Data and Preprocessing"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-05-06T00:00:03.405579Z","iopub.status.busy":"2023-05-06T00:00:03.405173Z","iopub.status.idle":"2023-05-06T00:00:03.415364Z","shell.execute_reply":"2023-05-06T00:00:03.413023Z","shell.execute_reply.started":"2023-05-06T00:00:03.40554Z"},"trusted":true},"outputs":[],"source":["def read_nifti_file(filepath):\n","    \"\"\"Read and load volume\"\"\"\n","    # Read file\n","    scan = nib.load(filepath)\n","    # Get raw data\n","    scan = scan.get_fdata()\n","    return scan\n","\n","\n","# def normalize(volume):\n","#     \"\"\"Normalize the volume\"\"\"\n","#     volume = (volume - np.min(volume)) / (np.max(volume) - np.min(volume))\n","#     return (volume * 255).astype(np.uint8)\n","\n","\n","def process_scan(path):\n","    \"\"\"Read and resize volume\"\"\"\n","    # Read scan\n","    volume = read_nifti_file(path)\n","    # Normalize\n","    # volume = normalize(volume)\n","    # Rotate by -90 degrees\n","    # volume = ndimage.rotate(volume, -90, axes=(0,1), reshape=False, order=1)\n","\n","    return volume"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[0. 1. 2. 4.]\n"]}],"source":["file_path = '/Users/choihanjun/Library/Mobile Documents/com~apple~CloudDocs/Downloads/2024-1/[강화학습]/Project/archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_seg.nii'\n","\n","processed_volume = process_scan(file_path)\n","unique_values = np.unique(processed_volume)\n","print(unique_values)"]},{"cell_type":"markdown","metadata":{},"source":["# Calculating the bbox of the image, using BFS Algorithm"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[-1, -1, -1, -1, -1, -1, -1, -1, -1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n","[-1, -1, -1, 0, 0, 0, 1, 1, 1, -1, -1, -1, 0, 0, 1, 1, 1, -1, -1, -1, 0, 0, 0, 1, 1, 1]\n","[-1, 0, 1, -1, 0, 1, -1, 0, 1, -1, 0, 1, -1, 1, -1, 0, 1, -1, 0, 1, -1, 0, 1, -1, 0, 1]\n"]}],"source":["object_list = []\n","# processed_volume.shape = (240, 240, 155)\n","dx = []\n","dy = []\n","dz = []\n","\n","for x in range(-1, 2):  # -1, 0, 1\n","    for y in range(-1, 2):\n","        for z in range(-1, 2):\n","            if x == 0 and y == 0 and z == 0:\n","                continue  # 중심점 제외\n","            dx.append(x)\n","            dy.append(y)\n","            dz.append(z)\n","\n","print(dx)\n","print(dy)\n","print(dz)            \n","    "]},{"cell_type":"code","execution_count":28,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["BBox from (66, 99, 39) to (119, 160, 82)\n","BBox from (75, 115, 53) to (75, 115, 53)\n","BBox from (112, 121, 50) to (112, 121, 50)\n"]}],"source":["from collections import deque\n","\n","\n","\n","def make_bbox(file_path):\n","    file_path = '/Users/choihanjun/Library/Mobile Documents/com~apple~CloudDocs/Downloads/2024-1/[강화학습]/Project/archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_seg.nii'\n","    processed_volume = process_scan(file_path)  \n","    visited = np.zeros(processed_volume.shape)\n","    len_z, len_y, len_x = processed_volume.shape\n","    \n","    def check(visited, nxt_z, nxt_y, nxt_x):\n","        # 밖으로 나가지 않았고, 방문하지 않았고, tumor이라면 nxt 방문 조건이 됨.\n","        if 0 <= nxt_z < visited.shape[0] and \\\n","            0 <= nxt_y < visited.shape[1] and \\\n","                0 <=  nxt_x < visited.shape[2] and \\\n","                    visited[nxt_z][nxt_y][nxt_x] != 1 and \\\n","                        processed_volume[nxt_z][nxt_y][nxt_x] == 4:\n","            return True\n","        else:\n","            return False\n","        \n","    def BFS(z, y, x):\n","        deq = deque([(z, y, x)])\n","        object_list = [(z, y, x)]\n","        while deq:\n","            now_pos = deq.popleft()\n","            for i in range(len(dx)):\n","                nxt_z, nxt_y, nxt_x = now_pos[0] + dz[i], now_pos[1] + dy[i], now_pos[2] + dx[i]\n","                if check(visited, nxt_z, nxt_y, nxt_x):\n","                    visited[nxt_z][nxt_y][nxt_x] = 1\n","                    deq.appendleft((nxt_z, nxt_y, nxt_x))\n","                    object_list.append((nxt_z, nxt_y, nxt_x))\n","                    \n","        if object_list:\n","            zs, ys, xs = zip(*object_list)\n","            min_z, max_z, min_y, max_y, min_x, max_x = min(zs), max(zs), min(ys), max(ys), min(xs), max(xs)\n","            # z, y, x, height, width, depth(?)\n","            return min_z, min_y, min_x, max_z - max_z, max_y - min_y, max_x - min_x\n","        else:\n","            return None\n","    \n","    \n","    for z in range(len_z):\n","        for y in range(len_y):\n","            for x in range(len_x):\n","                if check(visited, z, y, x):\n","                    bbox = BFS(z, y, x)\n","                    if bbox:\n","                        print(f\"BBox from ({bbox[0]}, {bbox[1]}, {bbox[2]}) to ({bbox[3]}, {bbox[4]}, {bbox[5]})\")\n","                    else:\n","                        print(\"No object found at this starting point\")\n","                    \n","    \n","\n","\n","\n","make_bbox(' ')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["368\n","defaultdict(<class 'int'>, {(240, 240, 155): 368})\n"]}],"source":["from collections import defaultdict\n","from glob import glob\n","import nibabel as nib\n","from scipy import ndimage\n","DATA_PATH = '../archive_BraTS2022'\n","TRAIN_PATH = f'{DATA_PATH}/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData'\n","file_path = '/Users/choihanjun/Library/Mobile Documents/com~apple~CloudDocs/Downloads/2024-1/[강화학습]/Project/archive_BraTS2022/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_001/BraTS20_Training_001_seg.nii'\n","\n","shape_dict = defaultdict(int)\n","\n","print(len(glob(f'{TRAIN_PATH}/*/*seg.nii', recursive=True)))\n","\n","for file_path in glob(f'{TRAIN_PATH}/*/*seg.nii', recursive=True):\n","    processed_volume = process_scan(file_path)\n","    shape_dict[processed_volume.shape] += 1\n","    \n","print(shape_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":751906,"sourceId":1299795,"sourceType":"datasetVersion"}],"dockerImageVersionId":30458,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
